{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "euOZxlIMhstX"
   },
   "source": [
    "# Introduction to Automation with LangChain, Generative AI, and Python\n",
    "**1.1: Langchain**\n",
    "* Instructor: [Jeff Heaton](https://youtube.com/@HeatonResearch), WUSTL Center for Analytics and Business Insight (CABI), [Washington University in St. Louis](https://olin.wustl.edu/faculty-and-research/research-centers/center-for-analytics-and-business-insight/index.php)\n",
    "* For more information visit the [class website](https://github.com/jeffheaton/cabi_genai_automation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pC9A-LaYhsta"
   },
   "source": [
    "# 1.1: Introduction to LangChain\n",
    "\n",
    "One of the most intriguing and promising developments in the evolving landscape of language models and artificial intelligence is LangChain. This technology represents a significant leap forward in how we interact with and harness the capabilities of large language models (LLMs). As we delve into the intricacies of LangChain in this chapter, it's important to understand not just the technical underpinnings but also the user experience that makes it so revolutionary.\n",
    "\n",
    "## LangChain Chat Conversation Format\n",
    "\n",
    "To explore LangChain comprehensively, we will adopt a format that has become increasingly familiar and effective in LLMs: the chat conversation interface. This interactive style, reminiscent of how many of us communicate daily, offers a unique and accessible means to illustrate LangChain's capabilities, potential applications, and the nuances of its operation.\n",
    "\n",
    "We begin by importing the components from the LangChain library to support a chat-style interface to Bedrock. We will use the ChatBedrock interface for the Bedrock family of LLM models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "K2lC_JK3guaj"
   },
   "outputs": [],
   "source": [
    "# Conversation Style Inteface\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmWHTAub0sTm"
   },
   "source": [
    "The conversation format consists of arrays of chat entries of the following three types:\n",
    "\n",
    "* **SystemMessage** - This class designates the system prompt that provides instructions to the AI on the nature of the conversation and hints and guidelines. Generally, there will be only one system message at the beginning of the array.\n",
    "* **HumanMessage** - This class designates the chat messages from outside the LLM, typically the human user.\n",
    "* **AIMessage** - This class designates the chat messages from the LLM as responses to the HumanMessage messages.\n",
    "\n",
    "Here we see the chain to ask a simple question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "V_sJoVYAtE6b"
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a helpful assistant that concisely and accurately.\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"What is the capital of France?\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "To7rZtUO4B8t"
   },
   "source": [
    "We now submit these messages and retrieve the output from the model. We will use the older and less expensive Titan model, which is good enough for this query. Further, we use a zero temperature; we are simply looking for a factual answer, and creativity is not a goal or concern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xfb875JhtI6J",
    "outputId": "f4e120de-7a83-4b82-e10c-d8c3f990322b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model response:\n",
      " The capital of France is Paris.\n",
      "-----------\n",
      "{'model_id': 'amazon.titan-text-lite-v1', 'usage': {'prompt_tokens': 26, 'completion_tokens': 7, 'total_tokens': 33}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "MODEL = 'amazon.titan-text-lite-v1'\n",
    "#MODEL = 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "#MODEL = 'mistral.mistral-7b-instruct-v0:2'\n",
    "\n",
    "# Initialize bedrock, use built in role\n",
    "llm = ChatBedrock(\n",
    "    model_id=MODEL,\n",
    "    model_kwargs={\"temperature\": 0.1},\n",
    ")\n",
    "\n",
    "print(\"Model response:\")\n",
    "output = llm.invoke(messages)\n",
    "print(output.content)\n",
    "print(\"-----------\")\n",
    "print(output.response_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "be6a0hXj4lHj"
   },
   "source": [
    "The model that LangChain returns to you returns additional metadata. This data shows the token usage, which might be useful for estimating the total cost expected from this query.\n",
    "\n",
    "We can continue to grow this conversation if we wish. To do so, we added the model's response and another human question. Here, we will ask the model if it was sure about its last response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2vJuMVHZ1jJ8",
    "outputId": "d34c6945-9d2b-41c4-8e02-33b5056a72d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SystemMessage : You are a helpful assistant that concisely and accurately.\n",
      "HumanMessage : What is the capital of France?\n",
      "AIMessage :  The capital of France is Paris.\n",
      "HumanMessage : Are you sure, I think it was renamed for some reason?\n"
     ]
    }
   ],
   "source": [
    "messages.append(output)\n",
    "messages.append(HumanMessage(content=\"Are you sure, I think it was renamed for some reason?\"))\n",
    "for message in messages:\n",
    "    print(f\"{type(message).__name__} : {message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8Z7DZRH5TFr"
   },
   "source": [
    "We can submit the conversation array to the model and see its latest response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9qFxkEmAz1w1",
    "outputId": "f1928a10-db7f-4abc-92af-23e24cd8ecb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model response:\n",
      " Paris is the capital of France. It has been the capital since 1792.\n"
     ]
    }
   ],
   "source": [
    "print(\"Model response:\")\n",
    "output = llm.invoke(messages)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9nvX9oA3a0Z"
   },
   "source": [
    "## Asking a Single Question\n",
    "\n",
    "If you wish to ask the model a single question, not as part of a conversation chain, you can pass a string to the model for a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "34-95k0qg8ss",
    "outputId": "5d93f5a9-1ba6-4b52-d3ec-a4a8fa76451f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The five largest cities in the USA by population are: New York City, Los Angeles, Chicago, Houston, and Phoenix.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the question\n",
    "question = \"What are the five largest cities in the USA by population?\"\n",
    "\n",
    "# Use Langchain to call the API\n",
    "# The method and parameters might differ based on the Langchain version\n",
    "response = llm.invoke(question)\n",
    "\n",
    "# Print the response\n",
    "display(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_o2EkUkN3hEX"
   },
   "source": [
    "## Prompt Templates\n",
    "\n",
    "LangChain allows you to create chains of operations typically performed as part of an LLM-enabled application. One of these operations is a prompt template, which allows you to insert text into a previously created prompt. In this example, we will create a prompt template that asks the model to create a random blog post title.\n",
    "\n",
    "```\n",
    "Return only the title of a blog post article title on the topic of {topic} in {language}\n",
    "```\n",
    "\n",
    "To accomplish this objective, we will use a **PromptTemplate** object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L-g3zOXBmulc",
    "outputId": "fb7a08ec-2f47-4526-9605-c0116289334f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mReturn only the title of a blog post article title on the topic of pets for data scientists in english\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'topic': 'pets for data scientists', 'language': 'english', 'text': ' You can find the title of a blog post article by using the following query in English:\\n\\n```\\n\"title\": {\"$regex\": \"\\\\\\\\b(pet|dogs|cats|animals|pet food|pet shop|pet health|pet grooming|pet accessories|pet supplies|pet training|pet lifestyle|pet adoption|pet shop online|pet names|pet grooming tips|pet health tips|pet photos|pet care tips|pet tricks|pet training tricks|pet lover|pet blog|pet care advice|pet nutrition|pet shop advice|pet shop tips|pet advice|pet tips|pet life|'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "# Higher temperature, more creative\n",
    "llm = ChatBedrock(\n",
    "    model_id=MODEL,\n",
    "    model_kwargs={\"temperature\": 0.9},\n",
    ")\n",
    "\n",
    "topic = \"pets for data scientists\"\n",
    "language = \"english\"\n",
    "\n",
    "title_template = PromptTemplate( input_variables = ['topic', 'language'],\\\n",
    "  template = 'Return only the title of a blog post article title on the topic of {topic} in {language}' )\n",
    "title_chain = LLMChain(llm=llm, prompt=title_template, verbose=True)\n",
    "response = title_chain.invoke({'topic':topic,'language':language })\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOpAcj-byBPg"
   },
   "source": [
    "## Create a Simple Sequential Chain\n",
    "\n",
    "We will now use LangChain to tie multiple LLM calls into a longer chain using the **SimpleSequentialChain** class. We will use two smaller chains to create a title and body text for a blog post. We begin by defining the two prompts we will use to construct this blog post. Also, note that we request that the LLM utilize [markdown](https://en.wikipedia.org/wiki/Markdown) to generate the actual blog post.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ELS-9JD3Sao6"
   },
   "outputs": [],
   "source": [
    "# Create the two prompt templates\n",
    "title_template = PromptTemplate( input_variables = ['topic'], template = 'Give me a blog post title on {topic} in English' )\n",
    "article_template = PromptTemplate( input_variables = ['title'], template = 'Write a blog post for {title}, format in markdown.' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3vy7jf3-_xl"
   },
   "source": [
    "We will create the first chain to generate the random title. Here, we allow the user to specify the topic. We use a higher temperature to increase the creativity of the title. We also use a simpler model to minimize cost for the relatively simple task of title selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_KV8UJUDyP8M"
   },
   "outputs": [],
   "source": [
    "MODEL = 'amazon.titan-text-lite-v1'\n",
    "\n",
    "# Higher temperature, more creative\n",
    "llm = ChatBedrock(\n",
    "    model_id=MODEL,\n",
    "    model_kwargs={\"temperature\": 0.9},\n",
    ")\n",
    "title_chain = LLMChain(llm=llm, prompt=title_template, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cO0ielMf_xRa"
   },
   "source": [
    "Next, we compose the actual blog post; we will use a lower temperature to decrease creativity and cause the LLM to stick to factual information and avoid hallucinations. We also use a more complex model to provide a better article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "G7OCQCggyHlB"
   },
   "outputs": [],
   "source": [
    "MODEL2 = 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "\n",
    "# Create the article chain, stronger mode, still creative\n",
    "llm2 = ChatBedrock(\n",
    "    model_id=MODEL2,\n",
    "    model_kwargs={\"temperature\": 0.9},\n",
    ")\n",
    "article_chain = LLMChain(llm=llm2, prompt=article_template, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rftFvMyBa4-"
   },
   "source": [
    "Now, we combine these two chains into one. The input to the first chain will be the selected topic. The first chain will then output the title to the second chain, which will, in turn, output the actual article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2ibHBt4eyKZt"
   },
   "outputs": [],
   "source": [
    "# Create a complete chain to create a new blog post\n",
    "complete_chain=SimpleSequentialChain(chains=[title_chain, article_chain], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_7P-n_DBvpD"
   },
   "source": [
    "We can now display the final article. In this case, we requested an article on \"photography,\" and displayed the final article's markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mwro_kfKXvml",
    "outputId": "d0118b4d-9c33-4882-8d5a-0fe4eb42ad59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGive me a blog post title on photography in English\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m Sure, I can help you with that. Here's a blog post title on photography in English:\n",
      "\n",
      "\"How to Take Professional-Looking Photos with Your Phone: A Beginner's Guide\"\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a blog post for  Sure, I can help you with that. Here's a blog post title on photography in English:\n",
      "\n",
      "\"How to Take Professional-Looking Photos with Your Phone: A Beginner's Guide\", format in markdown.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m# How to Take Professional-Looking Photos with Your Phone: A Beginner's Guide\n",
      "\n",
      "In today's world, where smartphones have become an integral part of our daily lives, the art of photography has become more accessible than ever before. With the advancements in mobile camera technology, it's now possible to capture stunning, professional-looking photos right from your phone. Whether you're an aspiring photographer or simply someone who enjoys capturing memorable moments, this beginner's guide will help you elevate your mobile photography game.\n",
      "\n",
      "## Master the Basics\n",
      "\n",
      "Before diving into advanced techniques, it's essential to understand the fundamentals of photography. Start by learning about the exposure triangle, which consists of aperture, shutter speed, and ISO. While most smartphones don't allow you to manually adjust these settings, understanding how they work will help you make informed decisions when using your phone's camera.\n",
      "\n",
      "## Explore Your Phone's Camera Features\n",
      "\n",
      "Most modern smartphones come equipped with a variety of camera features and modes. Take some time to explore these features and experiment with different settings. For example, try using the portrait mode to achieve a beautiful bokeh effect (blurred background) or the panorama mode to capture stunning landscapes.\n",
      "\n",
      "## Compose Your Shots\n",
      "\n",
      "Composition is a crucial element in photography, and it can make or break a photo. Follow the rule of thirds, which suggests dividing your frame into thirds horizontally and vertically, and positioning your subject along these lines or at their intersections. Additionally, consider leading lines, symmetry, and framing to create visually appealing compositions.\n",
      "\n",
      "## Take Advantage of Natural Light\n",
      "\n",
      "Natural light is one of the most beautiful and versatile light sources for photography. Whenever possible, try to shoot in natural light conditions, such as during the golden hours (shortly after sunrise or before sunset) or on overcast days, which provide soft, diffused light. If shooting indoors, position your subject near a window or use reflectors to bounce light onto your subject.\n",
      "\n",
      "## Edit and Enhance Your Photos\n",
      "\n",
      "While it's important to capture great shots in-camera, post-processing can take your photos to the next level. Explore the editing tools available on your phone or download third-party photo editing apps. These apps can help you adjust exposure, contrast, saturation, and more, allowing you to bring out the best in your photographs.\n",
      "\n",
      "## Practice, Practice, Practice\n",
      "\n",
      "Like any skill, photography requires practice. The more you shoot, the more you'll develop an eye for composition, lighting, and other essential elements. Carry your phone with you wherever you go and capture everything that catches your eye. Experiment with different angles, perspectives, and settings to find your unique style.\n",
      "\n",
      "Remember, taking professional-looking photos with your phone is a journey, and with dedication and practice, you'll be amazed at the stunning results you can achieve. So, grab your phone, embrace your creativity, and start capturing the world around you in a whole new light!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display_markdown\n",
    "\n",
    "article = complete_chain.invoke('photography')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1pN8CbXCE6F"
   },
   "source": [
    "The actual display of the markdown is handled by this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "id": "Vt5uGJawuru_",
    "outputId": "7ff949a4-294f-43fb-afb7-7785aa22b673"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# How to Take Professional-Looking Photos with Your Phone: A Beginner's Guide\n",
       "\n",
       "In today's world, where smartphones have become an integral part of our daily lives, the art of photography has become more accessible than ever before. With the advancements in mobile camera technology, it's now possible to capture stunning, professional-looking photos right from your phone. Whether you're an aspiring photographer or simply someone who enjoys capturing memorable moments, this beginner's guide will help you elevate your mobile photography game.\n",
       "\n",
       "## Master the Basics\n",
       "\n",
       "Before diving into advanced techniques, it's essential to understand the fundamentals of photography. Start by learning about the exposure triangle, which consists of aperture, shutter speed, and ISO. While most smartphones don't allow you to manually adjust these settings, understanding how they work will help you make informed decisions when using your phone's camera.\n",
       "\n",
       "## Explore Your Phone's Camera Features\n",
       "\n",
       "Most modern smartphones come equipped with a variety of camera features and modes. Take some time to explore these features and experiment with different settings. For example, try using the portrait mode to achieve a beautiful bokeh effect (blurred background) or the panorama mode to capture stunning landscapes.\n",
       "\n",
       "## Compose Your Shots\n",
       "\n",
       "Composition is a crucial element in photography, and it can make or break a photo. Follow the rule of thirds, which suggests dividing your frame into thirds horizontally and vertically, and positioning your subject along these lines or at their intersections. Additionally, consider leading lines, symmetry, and framing to create visually appealing compositions.\n",
       "\n",
       "## Take Advantage of Natural Light\n",
       "\n",
       "Natural light is one of the most beautiful and versatile light sources for photography. Whenever possible, try to shoot in natural light conditions, such as during the golden hours (shortly after sunrise or before sunset) or on overcast days, which provide soft, diffused light. If shooting indoors, position your subject near a window or use reflectors to bounce light onto your subject.\n",
       "\n",
       "## Edit and Enhance Your Photos\n",
       "\n",
       "While it's important to capture great shots in-camera, post-processing can take your photos to the next level. Explore the editing tools available on your phone or download third-party photo editing apps. These apps can help you adjust exposure, contrast, saturation, and more, allowing you to bring out the best in your photographs.\n",
       "\n",
       "## Practice, Practice, Practice\n",
       "\n",
       "Like any skill, photography requires practice. The more you shoot, the more you'll develop an eye for composition, lighting, and other essential elements. Carry your phone with you wherever you go and capture everything that catches your eye. Experiment with different angles, perspectives, and settings to find your unique style.\n",
       "\n",
       "Remember, taking professional-looking photos with your phone is a journey, and with dedication and practice, you'll be amazed at the stunning results you can achieve. So, grab your phone, embrace your creativity, and start capturing the world around you in a whole new light!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_key = complete_chain.output_key\n",
    "\n",
    "display_markdown(article[output_key], raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
