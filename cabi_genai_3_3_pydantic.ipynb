{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whjsJasuhstV"
   },
   "source": [
    "# Introduction to Automation with LangChain, Generative AI, and Python\n",
    "**3.3: Pydantic Parser**\n",
    "* Instructor: [Jeff Heaton](https://youtube.com/@HeatonResearch), WUSTL Center for Analytics and Business Insight (CABI), [Washington University in St. Louis](https://olin.wustl.edu/faculty-and-research/research-centers/center-for-analytics-and-business-insight/index.php)\n",
    "* For more information visit the [class website](https://github.com/jeffheaton/cabi_genai_automation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pC9A-LaYhsta"
   },
   "source": [
    "Pydantic is a data validation and settings management library in Python that uses Python type annotations. It's designed to allow for quick and easy data parsing and validation using Python's standard typing system.\n",
    "\n",
    "Some of the key features of Pydantic:\n",
    "\n",
    "* Data validation: It validates data to ensure it conforms to the expected format, converting types where necessary.\n",
    "* Editor support: Pydantic models are classes that leverage Python's type hints, making them easy to use with modern editors that provide features like type checking and autocompletion.\n",
    "* Error handling: It provides detailed and human-readable error reports to help identify where and why data failed to validate.\n",
    "* Settings management: Pydantic is often used for managing settings/configurations, making it easy to load parameters from environment variables, JSON files, or other sources.\n",
    "* Extensible: You can extend models with methods and properties, and use Pydantic's validation decorators to perform custom validation.\n",
    "* Integration with other libraries: It works well with many other libraries, such as FastAPI for building APIs, enhancing their usability and functionality.\n",
    "\n",
    "Overall, Pydantic is highly appreciated for its robustness and ease of use in ensuring that data inputs conform to specified formats, making it a valuable tool in modern Python development, especially in web development and data processing applications.\n",
    "\n",
    "LangChain, a library designed to facilitate the building of applications with language models, offers various tools to manage and enhance interactions with these models. One of these tools is the PydanticOutputParser, which integrates Pydantic's powerful validation capabilities with the output of large language models (LLMs) like GPT.\n",
    "\n",
    "The primary goal of the PydanticOutputParser is to ensure that the outputs from a language model are structured and adhere to a predefined schema. This is especially important in applications where consistent and reliable data formats are crucial, such as in data extraction tasks, API responses, or any scenario requiring subsequent automated processing of the model's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "O_J3QNntH18p"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "MODEL = 'mistral.mistral-7b-instruct-v0:2'\n",
    "# Initialize bedrock, use built in role\n",
    "llm = ChatBedrock(\n",
    "    model_id=MODEL,\n",
    "    model_kwargs={\"temperature\": 0.5},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUsS8qUHO2oc"
   },
   "source": [
    "The following code uses an LLM to tell a joke. The pydantic parser ensures that the joke ends in a question mark. Such checking ensures that the somewhat random LLM produces output that aligns with our expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tn-F_KZQI9WK",
    "outputId": "8784a6cf-6e23-4930-eed2-a510831b7fe7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='Why was the cat sitting on the computer keyboard?', punchline='He wanted to purr-use the internet!')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "    # You can add custom validation logic easily with Pydantic.\n",
    "    @validator(\"setup\")\n",
    "    def question_ends_with_question_mark(cls, field):\n",
    "        if field[-1] != \"?\":\n",
    "            raise ValueError(\"Badly formed question!\")\n",
    "        return field\n",
    "\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke about cats.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fl9oeUkBPsIu"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SOwX3ue7JH5v",
    "outputId": "a7696808-720b-4bb0-a16f-2d5d81dbda93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Actor(name='Julia Roberts', film_names=['Pretty Woman', 'Sleeping with the Enemy', 'Mystic Pizza', 'Notting Hill', 'Erin Brockovich', \"Ocean's Eleven\", 'The Mexican', 'Full Circle', 'Mona Lisa Smile', \"Charlie Wilson's War\", 'Duplicity', 'Eat Pray Love', 'August: Osage County', 'Money Monster', \"Mother's Day\"])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Actor(BaseModel):\n",
    "    name: str = Field(description=\"name of an actor\")\n",
    "    film_names: List[str] = Field(description=\"list of names of films they starred in\")\n",
    "    @validator('name')\n",
    "    def validate_name(cls, value):\n",
    "        parts = value.split()\n",
    "        if len(parts) < 2:\n",
    "            raise ValueError(\"Name must contain at least two words.\")\n",
    "        if not all(part[0].isupper() for part in parts):\n",
    "            raise ValueError(\"Each word in the name must start with a capital letter.\")\n",
    "        return value\n",
    "\n",
    "actor_query = \"Generate the filmography for Julia Roberts.\"\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Actor)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "chain.invoke({\"query\": actor_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
