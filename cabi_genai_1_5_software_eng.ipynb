{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whjsJasuhstV"
   },
   "source": [
    "# Introduction to Automation with LangChain, Generative AI, and Python\n",
    "**1.5: Tracking Prompts in Software Development**\n",
    "* Instructor: [Jeff Heaton](https://youtube.com/@HeatonResearch), WUSTL Center for Analytics and Business Insight (CABI), [Washington University in St. Louis](https://olin.wustl.edu/faculty-and-research/research-centers/center-for-analytics-and-business-insight/index.php)\n",
    "* For more information visit the [class website](https://github.com/jeffheaton/cabi_genai_automation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pC9A-LaYhsta"
   },
   "source": [
    "Prompting will undoubtedly become an essential part of modern software engineering. Programmers will likely construct individual prompts to generate methods. In this part, we will see how to write a prompt that consistently produces a non-trivial image cropping function. We will also store the prompt with the function so we do not lose the prompt in the future. Additionally, we will use automated unit tests to ensure that the generated method initially does what we expect, and continues to do so in the future, even if the technique is regenerated.\n",
    "\n",
    "## Conversational Code Generation\n",
    "\n",
    "We will continue to use the conversational code generation function provided in Module 2.2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TMF-rtxgRAea"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain_core.prompts.chat import PromptTemplate\n",
    "from IPython.display import display_markdown\n",
    "\n",
    "MODEL = 'meta.llama2-70b-chat-v1'\n",
    "TEMPLATE = \"\"\"The following is a friendly conversation between a human and an\n",
    "AI to generate Python code. If you have notes about the code, place them before\n",
    "the code. Any nots about execution should follow the code. If you do mix any\n",
    "notes with the code, make them comments. Add proper comments to the code.\n",
    "Sort imports and follow PEP-8 formatting.\n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "Human: {input}\n",
    "Code Assistant:\"\"\"\n",
    "PROMPT_TEMPLATE = PromptTemplate(input_variables=[\"history\", \"input\"], template=TEMPLATE)\n",
    "\n",
    "def start_conversation():\n",
    "    # Initialize bedrock, use built in role\n",
    "    llm = ChatBedrock(\n",
    "        model_id=MODEL,\n",
    "        model_kwargs={\"temperature\": 0.1},\n",
    "    )\n",
    "\n",
    "    # Initialize memory and conversation\n",
    "    memory = ConversationBufferWindowMemory()\n",
    "    conversation = ConversationChain(\n",
    "        prompt=PROMPT_TEMPLATE,\n",
    "        llm=llm,\n",
    "        memory=memory,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    return conversation\n",
    "\n",
    "def generate_code(conversation, prompt):\n",
    "    print(\"Model response:\")\n",
    "    output = conversation.invoke(prompt)\n",
    "    display_markdown(output['response'], raw=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ze2LsFCScSQW"
   },
   "source": [
    "## Prompts for Consistent Code Generation\n",
    "\n",
    "The code below shows the prompt I created to generate the clipping function. It is essential to specify very clearly what you want from the LLM. In this case, I made sure to specify:\n",
    "\n",
    "* The name of the function\n",
    "* The name of all arguments to that function\n",
    "* What to return\n",
    "* The exact algorithm, including how to handle negative values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 799
    },
    "id": "6bkupDjIbni5",
    "outputId": "ecdeeb80-5e60-420d-9985-4304e6eae56a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "  Sure, here's a possible implementation of the `safe_clip` function:\n",
       "```\n",
       "import cv2\n",
       "import numpy as np\n",
       "\n",
       "def safe_clip(cv2_image, x, y, width, height, background):\n",
       "    \"\"\"\n",
       "    Clips a region from an OpenCV image while adjusting for boundaries and filling\n",
       "    any areas missing from the original image boundaries with a specified color.\n",
       "    \n",
       "    Parameters:\n",
       "        cv2_image (numpy.ndarray): The OpenCV image to clip.\n",
       "        x (int): The x-coordinate of the top-left corner of the clipping region.\n",
       "        y (int): The y-coordinate of the top-left corner of the clipping region.\n",
       "        width (int): The width of the clipping region.\n",
       "        height (int): The height of the clipping region.\n",
       "        background (numpy.ndarray): The color to fill missing areas with.\n",
       "    \n",
       "    Returns:\n",
       "        tuple: A tuple containing the following elements:\n",
       "            - new_image (numpy.ndarray): The clipped image.\n",
       "            - x_offset (int): The x-coordinate of the shifted origin of the clipped image.\n",
       "            - y_offset (int): The y-coordinate of the shifted origin of the clipped image.\n",
       "    \n",
       "    Notes:\n",
       "        - The function will adjust the coordinates and size of the clipping region to fit within the image dimensions.\n",
       "        - The function will fill any areas missing from the original image boundaries with the specified background color.\n",
       "        - The return type is a tuple of three elements: the new image, and the x and y offsets of the shifted origin.\n",
       "    \n",
       "    Examples:\n",
       "        >>> cv2_image = cv2.imread('image.jpg')\n",
       "        >>> x, y, width, height = 100, 100, 300, 300\n",
       "        >>> background = np.array([255, 255, 255])\n",
       "        >>> new_image, x_offset, y_offset = safe_clip(cv2_image, x, y, width, height, background)\n",
       "        >>> cv2.imshow('Clipped Image', new_image)\n",
       "        >>> cv2.waitKey(0)\n",
       "        >>> cv2."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conversation = start_conversation()\n",
    "generate_code(conversation,\"\"\"\n",
    "Write a Python function named safe_clip using the PEP-8 style guide. The function\n",
    "should accept five parameters: cv2_image, x, y, width, height, and background.\n",
    "The imports should be sorted alphabetically.\n",
    "\n",
    "The purpose of this function is to clip a region from an OpenCV image while a\n",
    "djusting for boundaries and filling any areas missing from the original image\n",
    "boundaries with a specified color. Ensure that the code includes comments and a\n",
    "docstring explaining the functionality in detail.\n",
    "\n",
    "The function should:\n",
    "\n",
    "Calculate the dimensions of the clipping region and adjust them if they extend\n",
    "beyond the image boundaries. Negative x and y indicate that the source image\n",
    "must be expanded to accomodate the these coordinate that were outside the image.\n",
    "Create a new image of the specified size, filled with the background color.\n",
    "Place the clipped region into the newly created image at the appropriate location.\n",
    "Return a tuple containing the new image, along with x and y offsets indicating\n",
    "how much the origin of the clipped image has shifted relative to the original image.\n",
    "The return type should be specified in the function's docstring, which should\n",
    "also detail the types and purposes of each parameter. Additionally, mention that\n",
    "the function will adjust coordinates and size to fit within the image dimensions and\n",
    "fill missing areas with the specified background color.\n",
    "\n",
    "Include a detailed example in the docstring illustrating how the function is\n",
    "called and what it returns.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCmjBxIdcesJ"
   },
   "source": [
    "## Trying Out the Generated Code\n",
    "\n",
    "The code below shows the prompt I created to generate the clipping function. It is essential to specify very clearly what you want from the LLM. In this case, I made sure to specify:\n",
    "\n",
    "* The name of the function\n",
    "* The name of all arguments to that function\n",
    "* What to return\n",
    "* The exact algorithm, including how to handle negative values\n",
    "\n",
    "The following code shows my function; I also embed the prompt inside the source as a comment. This way, I can track changes to both the function and prompt as I check both in a source code repository like GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "q42Lx21EcjTf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "## safe_clip was generated by the following prompt:\n",
    "# Write a Python function named safe_clip using the PEP-8 style guide. The function\n",
    "# should accept five parameters: cv2_image, x, y, width, height, and background.\n",
    "# The imports should be sorted alphabetically.\n",
    "#\n",
    "# The purpose of this function is to clip a region from an OpenCV image while a\n",
    "# djusting for boundaries and filling any areas missing from the original image\n",
    "# boundaries with a specified color. Ensure that the code includes comments and a\n",
    "# docstring explaining the functionality in detail.\n",
    "#\n",
    "# The function should:\n",
    "#\n",
    "# Calculate the dimensions of the clipping region and adjust them if they extend\n",
    "# beyond the image boundaries. Negative x and y indicate that the source image\n",
    "# must be expanded to accomodate the these coordinate that were outside the image.\n",
    "# Create a new image of the specified size, filled with the background color.\n",
    "# Place the clipped region into the newly created image at the appropriate location.\n",
    "# Return a tuple containing the new image, along with x and y offsets indicating\n",
    "# how much the origin of the clipped image has shifted relative to the original image.\n",
    "# The return type should be specified in the function's docstring, which should\n",
    "# also detail the types and purposes of each parameter. Additionally, mention that\n",
    "# the function will adjust coordinates and size to fit within the image dimensions and\n",
    "# fill missing areas with the specified background color.\n",
    "#\n",
    "# Include a detailed example in the docstring illustrating how the function is\n",
    "# called and what it returns.\n",
    "\n",
    "def safe_clip(cv2_image, x, y, width, height, background):\n",
    "    \"\"\"\n",
    "    Clips a region from an OpenCV image, adjusting for boundaries and filling missing areas.\n",
    "\n",
    "    Parameters:\n",
    "        cv2_image (numpy.ndarray): The source image from which to clip the region.\n",
    "        x (int): The x-coordinate of the top-left corner of the clipping region.\n",
    "        y (int): The y-coordinate of the top-left corner of the clipping region.\n",
    "        width (int): The width of the clipping region.\n",
    "        height (int): The height of the clipping region.\n",
    "        background (tuple): A tuple representing the BGR color (e.g., (255, 255, 255) for white) used to fill missing areas.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - new_image (numpy.ndarray): The new image with the clipped region and background.\n",
    "            - x_offset (int): The x-coordinate offset of the new image relative to the original image.\n",
    "            - y_offset (int): The y-coordinate offset of the new image relative to the original image.\n",
    "\n",
    "    Example:\n",
    "        >>> img = np.zeros((100, 100, 3), dtype=np.uint8)\n",
    "        >>> clipped_img, x_off, y_off = safe_clip(img, -10, -10, 120, 120, (255, 0, 0))\n",
    "        >>> print(clipped_img.shape, x_off, y_off)\n",
    "        ((120, 120, 3), 10, 10)\n",
    "    \"\"\"\n",
    "    # Calculate effective x, y, width, and height considering image boundaries\n",
    "    x_eff = max(x, 0)\n",
    "    y_eff = max(y, 0)\n",
    "    width_eff = min(width, cv2_image.shape[1] - x_eff)\n",
    "    height_eff = min(height, cv2_image.shape[0] - y_eff)\n",
    "\n",
    "    # Create a new image filled with the background color\n",
    "    new_image = np.full((height, width, 3), background, dtype=cv2_image.dtype)\n",
    "\n",
    "    # Calculate offsets if the requested region is out of the original image bounds\n",
    "    x_offset = -min(x, 0)\n",
    "    y_offset = -min(y, 0)\n",
    "\n",
    "    # Place the clipped part of the original image into the new image\n",
    "    new_image[y_offset:y_offset + height_eff, x_offset:x_offset + width_eff] = \\\n",
    "        cv2_image[y_eff:y_eff + height_eff, x_eff:x_eff + width_eff]\n",
    "\n",
    "    return new_image, x_offset, y_offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0U3wWY3jv1it"
   },
   "source": [
    "Now, I will create an image of a grayscale and show how the function performs on three different types of crops. One of the critical features of this cropping function is that it might expand the original image if the upper-left corner or lower-right corner is off of the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "id": "DcmhBIZQclni",
    "outputId": "78fd1db1-c906-4780-8255-7071709a818c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABOwAAAE1CAYAAABUTH/FAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAvg0lEQVR4nO3de7xVc94H8O8+3TtdVEqhQii3kIR4uiCTjEGixjQSuRTPMJNpeMbQYFBCngdjGPSYl3EdGhLDqIZRUeM2uYzHzFRjKIlcGrqcfs8ftbezz6VONy3m/X699uucs9Z3rfVba+/9O2t/9rrkUkopAAAAAIBMKNnSDQAAAAAAviCwAwAAAIAMEdgBAAAAQIYI7AAAAAAgQwR2AAAAAJAhAjsAAAAAyBCBHQAAAABkiMAOAAAAADJEYAcAAAAAGSKw20xmzpwZJ5xwQrRp0ybq1q0brVu3jgEDBsSMGTPWaz6jR4+OXC63QW2YNm1a5HK5mDZt2gZNX1O9evWKXr161ahuzz333KxtAYq98sorMXTo0Nhxxx2jfv360ahRo+jSpUuMHTs2Pvjgg0JdVe/jXC4Xo0eP/nIbvAF22GGHOOWUU6odX1ZWFltttVUceeSRlcZdd911kcvl4tvf/nalcZdddlnkcrl45ZVXqlzOO++8E6NHj46XXnqp0rSnnHJKNGrUqEbt39TbOf9/I/8oKSmJNm3aRL9+/eLZZ5/dZMvZXObOnRu5XC4mTJiwpZsCG0zfW9n7778f9erVi1wuF7Nnz66y5oorroiJEyfWeJ7l+7qKj5q07ZRTTokddtihxsuDrxL9ULHFixfHhRdeGLvvvns0bNgwmjRpEgceeGDceOONsWLFig1uw+TJkzd4W63PPs/G5AJVmTBhQqV+s2XLltGrV6+YNGnSJlvO5vRVeZ1ujNpbugFfR//zP/8T5513XnTr1i3Gjh0b7du3j/nz58eNN94YhxxySFx//fVxzjnn1Ghew4YNi759+25QO7p06RIzZsyI3XfffYOmB77abr311hgxYkR07NgxfvjDH8buu+8eK1asiNmzZ8fNN98cM2bMiIceeqja6WfMmBHbb7/9l9jizaNWrVrxH//xHzFt2rRYuXJl1K79xb++adOmRWlpaUydOrXSdNOmTYsWLVrEXnvtFRERDz30UDRp0qQw/p133omf/vSnscMOO8Q+++yzwe3bXNv58ccfj6ZNm8aqVati/vz5MXbs2OjVq1c899xz0aVLl02+PGA1fW/VfvWrX8Xy5csjIuK2226Lrl27Vqq54oorYsCAAXHsscfWeL4DBgyIkSNHVhresmXLDW4rfNXph4q98cYbccQRR8Snn34aI0eOjO7du8dnn30WkyZNinPPPTfuv//+mDx5cjRs2HC95z158uS48cYbNyg4atOmTcyYMSM6dOiw3tNuKnfccUd06tQpUkqxYMGCuOGGG+Loo4+Ohx9+OI4++ugt1i5WE9htYs8++2ycd9550a9fv3jooYeKPhgOGjQojjvuuDj33HNj3333jYMPPrja+fzrX/+Khg0bxvbbb7/BnWX+WwPg38+MGTNi+PDh0adPn5g4cWLUq1evMK5Pnz4xcuTIePzxx9c6j69T/9G7d++YNGlSzJ49u7Beq1atimeeeSaGDx8e48aNi9dffz122223iIhYvnx5zJgxI/r161f4NnPffffdLG3bXNt5v/32i6233joiIrp37x7dunWLDh06xAMPPCCwg81E31u922+/PVq1ahXt27ePu+++O6699tpo0KDBRs93m222+dpuM9gQ+qFiZWVlcfzxx8fHH38czz//fOy6666Fcf369YuePXvGoEGD4gc/+EHcfPPNX2rb6tWrt8W39Z577ln0BUrfvn2jWbNmcffddwvsMsApsZvYlVdeGblcLn7+858XhXUREbVr146bbropcrlcXHXVVYXh+cNbX3jhhRgwYEA0a9askLJXdejrsmXLYuTIkdG6deto2LBh9OjRI/70pz9VOiS4qlNi86dpvfXWW9GvX79o1KhRtG3bNkaOHBnLli0rWs5Pf/rTOOCAA6J58+bRpEmT6NKlS9x2222RUtpEW2v1YaznnHNO3HHHHdGxY8do0KBBdO3aNWbOnBkppbj66qtjxx13jEaNGsWhhx4ab731VtH0Tz75ZBxzzDGx/fbbR/369WPnnXeOM888M95///1Ky/rtb38bnTt3jnr16sVOO+0U119/fZXbN6UUN910U+yzzz7RoEGDaNasWQwYMCD+9re/bbL1hs3tiiuuiFwuF7fcckvRjlpe3bp141vf+tZa51HxMPP8ofNPPvlkDB06NJo3bx6lpaVx9NFHV3p/5E+Bf+aZZ+LAAw+MBg0axHbbbRc/+clPoqysrKh2+fLlcfnll0enTp2iXr160bJlyxg6dGgsWrSoqG7FihUxatSoQt93yCGHxPPPP1+j7dG7d++IiKL+8OWXX44PP/wwzjjjjGjTpk3RUXbPPfdcfPbZZ4XpIopPu5g2bVrsv//+ERExdOjQwqkEFb9drUlfW912njp1agwfPjy23nrraNGiRfTv3z/eeeedGq1vVZo2bRoREXXq1CkaPn/+/Bg8eHC0atUq6tWrF7vttltcc801sWrVqkJNdZdYqOpUjvX5P/POO+/EiSeeGI0bN46mTZvGwIEDY8GCBZXa/re//S0GDRoU2267bdSrVy+22WabOOyww6o8HRm2JH1v1Z577rmYM2dOfPe7343TTz89Pvroo/jNb35Tab2XLl0a//u//1voU2tyyZWamjBhQnTs2LHQz915551V1r399tsxYMCAaNy4cWy11Vbxne98J2bNmlXlaWuzZ8+Ob33rW9G8efOoX79+7LvvvnHfffdtsjbDhtAPFXvooYfitddeiwsuuKAorMsbOHBgHHHEEXHbbbcV9kFqut9zyimnxI033ljYZvnH3LlzIyLi/vvvjwMOOCCaNm0aDRs2jJ122ilOPfXUaueX9+ijj8Y+++wT9erVix133DHGjRtX5bptjs+t9evXj7p161baX/zggw9ixIgRsd1220XdunVjp512ih//+MdF+3ZrO8W34msq/zn81VdfjW9/+9vRtGnT2GabbeLUU0+Njz76qGjajz/+OE4//fRo0aJFNGrUKPr27RtvvvlmpWUsWrQozjjjjGjbtm3h9XTwwQfH73//+w3eHluaI+w2obKyspg6dWp07dq12qPi2rZtG/vtt19MmTIlysrKolatWoVx/fv3j0GDBsVZZ50VS5curXY5Q4cOjXvvvTdGjRoVhx56aLz22mtx3HHHxccff1yjdq5YsSK+9a1vxWmnnRYjR46Mp59+Oi677LJo2rRpXHzxxYW6uXPnxplnnhnt2rWLiNXX5fvP//zP+Oc//1lUt7EmTZoUL774Ylx11VWRy+XiRz/6URx11FExZMiQ+Nvf/hY33HBDfPTRR/GDH/wgjj/++HjppZcKIdtf//rXOOigg2LYsGHRtGnTmDt3blx77bVxyCGHxJ///OdCR/P4449H//79o0ePHnHvvffGypUrY9y4cbFw4cJK7TnzzDNjwoQJ8b3vfS/GjBkTH3zwQVx66aXRvXv3ePnll2ObbbbZZOsOm0NZWVlMmTIl9ttvv2jbtu0mn/9pp50Wffr0iV//+tfxj3/8Iy666KLo1atXvPLKK7HVVlsV6hYsWBCDBg2KCy64IC699NJ49NFH4/LLL48PP/wwbrjhhohYfZTbMcccE88880yMGjUqunfvHvPmzYtLLrkkevXqFbNnzy4cgXH66afHnXfeGeeff3706dMn5syZE/37949PPvlknW3ee++9o1mzZjF16tS44IILIiJi6tSp0aZNm9hll12iR48eMW3atBgxYkRhXEQUBXbldenSJe64444YOnRoXHTRRXHUUUdFRBT1/TXta6szbNiwOOqoowrb+Yc//GEMHjw4pkyZss5pI1a/DlauXFk4Jfaiiy6KevXqxYABAwo1ixYtiu7du8fy5cvjsssuix122CEmTZoU559/fvz1r3+Nm266qUbLqqgm6/7ZZ5/F4YcfHu+8805ceeWVseuuu8ajjz4aAwcOrDS/fv36RVlZWYwdOzbatWsX77//fkyfPj2WLFmyQe2DzUHfW73bbrstIiJOPfXUaNu2bZx33nlx2223xeDBgws1M2bMiEMPPTR69+4dP/nJTyIiii5DUJ2UUqxcubLS8Fq1ahX2FydMmBBDhw6NY445Jq655pr46KOPYvTo0bFs2bIoKfni+IWlS5dG796944MPPogxY8bEzjvvHI8//niV/dLUqVOjb9++ccABB8TNN98cTZs2jXvuuScGDhwY//rXv9br+n6wqeiHKnvyyScjItZ6qv2xxx4bTzzxREybNi0GDRpU4+3xk5/8JJYuXRoPPPBA0bXq86e6Dhw4MAYOHBijR4+O+vXrx7x589a5H/fUU0/FMcccEwcddFDcc889hf2fzfW5Nb+/mFKKhQsXxtVXXx1Lly6Nk046qVDz+eefR+/eveOvf/1r/PSnP43OnTvHM888E1deeWW89NJL8eijj9Z4m1V0/PHHx8CBA+O0006LP//5z3HhhRdGxOqjsiNW9/HHHntsTJ8+PS6++OLYf//949lnn63y2tTf/e5344UXXoif/exnseuuu8aSJUvihRdeiMWLF29w+7a4xCazYMGCFBFp0KBBa60bOHBgioi0cOHClFJKl1xySYqIdPHFF1eqzY/Le/XVV1NEpB/96EdFdXfffXeKiDRkyJDCsKlTp6aISFOnTi0MGzJkSIqIdN999xVN369fv9SxY8dq21xWVpZWrFiRLr300tSiRYu0atWqwriePXumnj17rnWd83V77LFH0bCISK1bt06ffvppYdjEiRNTRKR99tmnaDnjx49PEZFeeeWVKue/atWqtGLFijRv3rwUEem3v/1tYdz++++f2rZtm5YtW1YY9sknn6QWLVoUbd8ZM2akiEjXXHNN0bz/8Y9/pAYNGqRRo0atcz1hS6tpX1ReVe/jiEiXXHJJ4e877rgjRUQ67rjjiuqeffbZFBHp8ssvL5pfxfdhSimdfvrpqaSkJM2bNy+l9EXf9Zvf/KaobtasWSki0k033ZRSSun1119PEZG+//3vF9Xdddddlfq+6hx77LGptLQ0rVixIqWU0tFHH13YRjfddFNq2bJloc/p3bt3atWqVdH07du3L1pOvo133HFHpWWtT19b3XYeMWJEUd3YsWNTRKR33313reuZ/79R8dGkSZP04IMPFtVecMEFKSLSc889VzR8+PDhKZfLpb/85S8ppar/n6SU0t///vdK26Cm6/7zn/+82tdI+Xm+//77KSLS+PHj17resKXpe6u2dOnS1KRJk3TggQcWhg0ZMiTlcrn01ltvFdWWlpbWaJ55VfV1+cevfvWrlNLqfdhtt902denSpWi/cu7cualOnTqpffv2hWE33nhjioj02GOPFS3nzDPPrNTXderUKe27776F/yl53/zmN1ObNm1SWVlZjdcDNhX9UGV9+/ZNEZE+//zzamsee+yxFBFpzJgxKaX12+85++yziz5P5o0bNy5FRFqyZEm1y61qfgcccEDadttt02effVYY9vHHH6fmzZtv0s+t+ee04qNevXqFbZ938803V7lvN2bMmBQR6Yknnqh2ffIqvqby+6tjx44tqhsxYkSqX79+ob/OPzfXX399Ud3PfvazSvNs1KhROu+889a63l81TondAtKaU0ornop5/PHHr3PaP/zhDxERceKJJxYNHzBgQKVTcKuTy+UqnY/euXPnmDdvXtGwKVOmxOGHHx5NmzaNWrVqRZ06deLiiy+OxYsXx3vvvVejZdVE7969o7S0tPB3/hpSRx55ZNE2yg8v38733nsvzjrrrGjbtm3Url076tSpE+3bt4+IiNdffz0iVn9bOnv27Dj22GOjbt26hWkbNWpUaTtMmjQpcrlcDB48OFauXFl4tG7dOvbee+/Nfsdd+Cr4zne+U/R39+7do3379pVu3NC4ceNKp1ycdNJJsWrVqnj66acjYvV7bquttoqjjz666D23zz77ROvWrQvvufy8Ky77xBNPrHHf17t371i6dGnMmjWrcP26/OlWPXv2jEWLFsWrr74ay5Yti5kzZ1Z7dF1N1bSvrU7Fbde5c+eIiBpP//vf/z5mzZoVzz//fEyaNCkOP/zwGDRoUNFFpqdMmRK77757dOvWrWjaU045JVJKNT6ar6KarPvUqVOrfY2U17x58+jQoUNcffXVce2118aLL75YdLou/Lv4qva99913X3z88cdFp4GdeuqpkVKKO+64o0bzWJsTTzwxZs2aVenRr1+/iIj4y1/+Eu+8806cdNJJRfuV7du3j+7duxfN6w9/+EM0bty40g3fKt5J/K233oo33nijsF3Kb8N+/frFu+++G3/5y182et0ga76q/dC6VPf5fGPkL51y4oknxn333Rf//Oc/1zlNfj+1f//+Ub9+/cLwxo0bb7bPrXfeeWeh33zsscdiyJAhcfbZZxeOhIxYvb9YWlpadJZGRBSOJH7qqadqtKyqVLW/+/nnnxfyhuqe/4r7ixER3bp1iwkTJsTll18eM2fO3Ki7/2aFwG4T2nrrraNhw4bx97//fa11c+fOjYYNG0bz5s2Lhrdp02ady8gfzlnx8NbatWtHixYtatTOhg0bFnUAEasvePn5558X/n7++efjiCOOiIjVdxl69tlnY9asWfHjH/84IlafyrSpVNwO+VCtuuH5dq5atSqOOOKIePDBB2PUqFHx1FNPxfPPPx8zZ84sauOHH34YKaUqDwmuOGzhwoWF2jp16hQ9Zs6cWeW18SBratoXbajWrVtXOazi4eZVvefy0+ZrFy5cGEuWLClcK6P8Y8GCBYX3XL6+4rLXp+/LB3BTp06NF198MZYsWRI9e/aMiIjdd989WrZsGdOmTYuZM2dWun7dhqhJX7s2Fdcrfx2amva/e++9d3Tt2jX233//OOqoo+L++++PnXfeOc4+++xCzeLFi6v837PtttsWxm+Imqz74sWL1/oaycvlcvHUU0/FN77xjRg7dmx06dIlWrZsGd/73vfW65Q82Nz0vVW77bbbon79+tG3b99YsmRJLFmyJDp37hw77LBDTJgwodI1rdZXy5Yto2vXrpUe+f3I6tahqmHV9UtV7S9GRJx//vmVtl/+0gr2GdkS9EOV5S/vtLZtkr/m3KY8jbhHjx4xceLEWLlyZZx88smx/fbbx5577hl33313tdN8+OGHsWrVqhr1V5vqc+tuu+1W6Df79u0bv/jFL+KII46IUaNGFS49snjx4mjdunWlQLNVq1ZRu3btjTrldF37u4sXL67yua5qG917770xZMiQ+OUvfxkHHXRQNG/ePE4++eQqr4/8VeEadptQrVq1onfv3vH444/H22+/XeV17N5+++3405/+FEceeWTR9esiapbo51+oCxcujO22264wfOXKlZv03Ox77rkn6tSpE5MmTSr60DVx4sRNtoyNNWfOnHj55ZdjwoQJMWTIkMLwijemaNasWeRyuSrP+6/45t16660jl8vFM888U+VFWqsaBllTq1atOOyww+Kxxx6rti/aGFX901uwYEHsvPPORcPW9p7L92X5GypUd7eyxo0bF9UvWLBgg/u+PffcsxDK5W9c0KlTp8L4Hj16xNSpUwvz29jALmtKSkpijz32iPvvvz/ee++9aNWqVbRo0SLefffdSrX5m1vk7zKb/z9Q8aYRG/OBtEWLFlVeMLqq11f79u0L18B6880347777ovRo0fH8uXLv/Q7ukF19L2Vvfnmm/HHP/4xIr740FzR7373u8LRcJtD+XWoqOKwmvZL+b7xwgsvjP79+1e53I4dO25Qe2Fj6Icq69OnT9xyyy0xceLEwnWMK5o4cWLUrl27cObFptrvOeaYY+KYY44pnL1x5ZVXxkknnRQ77LBDHHTQQZXq859ba9Jfbc7PrZ07d47f/e538eabb0a3bt2iRYsW8dxzz0VKqSizeO+992LlypXr3F/c2EAv/1yXD+2q2kZbb711jB8/PsaPHx/z58+Phx9+OC644IJ477331nln5KxyhN0mduGFF0ZKKUaMGFHpG8OysrIYPnx4pJQKF1NcXz169IiI1elxeQ888ECVF9zdULlcLmrXrl0UKn722Wfxq1/9apMtY2PlO4uKndEvfvGLor9LS0uja9euMXHixFi+fHlh+KeffhqTJk0qqv3mN78ZKaX45z//WeW3tXvttddmWhvYtPJ90emnn170us9bsWJFPPLIIxs077vuuqvo7+nTp8e8efMq3c3vk08+iYcffrho2K9//esoKSkp9GXf/OY3Y/HixVFWVlbley7/gSc/74rLvu+++2rc9+VyuejZs2dMnz49nnzyycLRdXk9e/aMP/zhDzF16tTYdtttq7yTWHnre8TbllZWVhZ//vOfo169eoULuR922GHx2muvxQsvvFBUe+edd0YulyuEljvssENERLzyyitFdRWf3/XRu3fval8ja7PrrrvGRRddFHvttVeldsOWpu8tlg/ab7311pg6dWrRY/LkyVGnTp3ChcUjVverm7pP7dixY7Rp0ybuvvvuwmlvEasvLzB9+vSi2p49e8Ynn3wSjz32WNHwe+65p9I8d9lll3j55Zer3H5du3YthA3wZdMPFTvuuONi9913j6uuuqrKO4vee++98cQTT8SwYcMKR22tz35PTfYH69WrFz179owxY8ZERMSLL75YZV1paWl069YtHnzwwaKzEj755JNKz9nm/Nz60ksvRcTqI5gjVu8vfvrpp5UO3snfbfuwww6LiNVHVtavX7/Sdvvtb3+7wW3J74tWfP7Xtb/Yrl27OOecc6JPnz5f6f1FR9htYgcffHCMHz8+zjvvvDjkkEPinHPOiXbt2sX8+fPjxhtvjOeeey7Gjx9f6ZoZNbXHHnvEt7/97bjmmmuiVq1aceihh8arr74a11xzTTRt2rToTlcb46ijjoprr702TjrppDjjjDNi8eLFMW7cuEwdYdapU6fo0KFDXHDBBZFSiubNm8cjjzxSuBNQeZdeemkcddRR8Y1vfCPOPffcKCsri6uvvjoaNWoUH3zwQaHu4IMPjjPOOCOGDh0as2fPjh49ekRpaWm8++678cc//jH22muvGD58+Je5mrBBDjrooPj5z38eI0aMiP322y+GDx8ee+yxR6xYsSJefPHFuOWWW2LPPfesdD2Mmpg9e3YMGzYsTjjhhPjHP/4RP/7xj2O77bYrnAaU16JFixg+fHjMnz8/dt1115g8eXLceuutMXz48MKRFoMGDYq77ror+vXrF+eee25069Yt6tSpE2+//XZMnTo1jjnmmDjuuONit912i8GDB8f48eOjTp06cfjhh8ecOXNi3LhxNbqLYF7v3r3jgQceiCeeeKLo2hwRqz+oLV68OJ5++ukqr4tRUYcOHaJBgwZx1113xW677RaNGjWKbbfdtnA66Zb2pz/9KZo2bRoRq7/pvv322+ONN96I73//+4VvQL///e/HnXfeGUcddVRceuml0b59+3j00UfjpptuiuHDhxdCy9atW8fhhx8eV155ZTRr1izat28fTz31VDz44IMb3L6TTz45rrvuujj55JPjZz/7Weyyyy4xefLk+N3vfldU98orr8Q555wTJ5xwQuyyyy5Rt27dmDJlSrzyyivVflMOW4q+9wsrV66MO++8M3bbbbcYNmxYlTVHH310PPzww7Fo0aJo2bJl7LXXXjFt2rR45JFHok2bNtG4ceN1Hqm2cOHCwuVQymvSpEnsvvvuUVJSEpdddlkMGzYsjjvuuDj99NNjyZIlMXr06EqnVA0ZMiSuu+66GDx4cFx++eWx8847x2OPPVbol8rvZ//iF7+II488Mr7xjW/EKaecEtttt1188MEH8frrr8cLL7wQ999//1rbDZuLfqhYrVq14je/+U306dMnDjrooBg5cmQcdNBBsWzZsnjkkUfilltuiZ49e8Y111xTmGZ99nvywdiYMWMKZ9F17tw5Lr/88nj77bfjsMMOi+233z6WLFkS119/fdSpU6fSl8blXXbZZdG3b9/o06dPjBw5MsrKymLMmDFRWlq6WT63zpkzpxB8Ll68OB588MF48skn47jjjosdd9wxIlbvs914440xZMiQmDt3buy1117xxz/+Ma644oro169fHH744RERhWvq3X777dGhQ4fYe++94/nnn19nuLY2RxxxRPTo0SNGjRoVS5cuja5du8azzz5b6UCijz76KHr37h0nnXRSdOrUKRo3bhyzZs2Kxx9/vNojob8SvvTbXPybmDFjRhowYEDaZpttUu3atVOrVq1S//790/Tp0yvV5u+QsmjRomrHlff555+nH/zgB6lVq1apfv366cADD0wzZsxITZs2Lbp7TnV3iS0tLa3Rcm6//fbUsWPHVK9evbTTTjulK6+8Mt12220pItLf//73Qt3G3iX27LPPLhqWv7vM1VdfXTQ8vz73339/Ydhrr72W+vTpkxo3bpyaNWuWTjjhhDR//vxKd4xJKaWHHnoo7bXXXqlu3bqpXbt26aqrrkrf+973UrNmzSq19fbbb08HHHBAKi0tTQ0aNEgdOnRIJ598cpo9e/Y61xOy5KWXXkpDhgxJ7dq1S3Xr1k2lpaVp3333TRdffHF67733CnXrc4ewJ554In33u99NW221VWrQoEHq169f+r//+7+iafPv92nTpqWuXbumevXqpTZt2qT/+q//qnRHvRUrVqRx48alvffeO9WvXz81atQoderUKZ155plF8122bFkaOXJkpb6v4t1b1+a1114r3AVrzpw5ReNWrVpVuAPXrbfeWmnaqpZz9913p06dOqU6deoUba/16Wur286zZs0qqqvujmXVLaP8o3nz5umAAw5It99+e6U7F86bNy+ddNJJqUWLFqlOnTqpY8eO6eqrr65U9+6776YBAwak5s2bp6ZNm6bBgwen2bNnV3mX2Jqu+9tvv52OP/741KhRo9S4ceN0/PHHp+nTpxfNc+HChemUU05JnTp1SqWlpalRo0apc+fO6brrrksrV65c67aALUXfm9LEiRPXeYfnxx9/vOguhy+99FI6+OCDU8OGDVNErHP/smJfV/5x8MEHF9X+8pe/TLvsskuqW7du2nXXXdPtt9+ehgwZUnSX2JRSmj9/furfv39RvzR58uQq73r58ssvpxNPPDG1atUq1alTJ7Vu3Todeuih6eabb15ru+HLoB8q9v7776cLLrggderUqbCsbt26pRtuuCEtX768Un1N93uWLVuWhg0bllq2bJlyuVzhs/KkSZPSkUcembbbbrtUt27d1KpVq9SvX7/0zDPPFKat7q6qDz/8cOrcuXPR59aq9qNS2vDPrVXdJbZp06Zpn332Sddee22lu+ouXrw4nXXWWalNmzapdu3aqX379unCCy+sVPfRRx+lYcOGpW222SaVlpamo48+Os2dO7fau8RWzEDy7SqfNyxZsiSdeuqpaauttkoNGzZMffr0SW+88UbRPD///PN01llnpc6dO6cmTZqkBg0apI4dO6ZLLrkkLV26dK3bIstyKZU7NpyvrOnTp8fBBx8cd911V42ODGH14eD77LNPbLfddvHEE09s6eZA5k2YMCGGDh0as2bNiq5du661tlevXvH+++/HnDlzvqTWAXw96Xu3vCuuuCIuuuiimD9//ia/Jhh8FeiHYMtwSuxX0JNPPhkzZsyI/fbbLxo0aBAvv/xyXHXVVbHLLrt8tQ/33MxOO+206NOnT7Rp0yYWLFgQN998c7z++utx/fXXb+mmAQCQAfnLJXTq1ClWrFgRU6ZMif/+7/+OwYMHC+sA+FIJ7L6CmjRpEk888USMHz8+Pvnkk9h6663jyCOPjCuvvLLojq4U++STT+L888+PRYsWRZ06daJLly4xefLkwjn3AAD8e2vYsGFcd911MXfu3Fi2bFm0a9cufvSjH8VFF120pZsGwL8Zp8QCAAAAQIZsmluKAgAAAACbhMAOAAAAADJEYAcAAAAAGVLjm07kcrmi36t7RESUlJQU/Z3L5aKkpKRG0+ZrazJ+bfOraW1N5mW9rJf12rDaWrVqxddNxVvZ57d9eRXXO2s1VT0vFafb0jVZ34a2c3ZqtvQ2rElNt27dKg37Ohg9enREVO7/88P8n/w3Xa8ZM6Jk1KjIzZy5MS8vvq6+jpdPz+XWXQNQXg37QkfYAQAAAECGCOwAAAAAIEMEdgAAAACQIQI7AAAAAMgQgR0AAAAAZIjADgAAAAAyRGAHAAAAABkisAMAAACADBHYAQAAAECGCOwAAAAAIEMEdgAAAACQIQI7AAAAAMgQgR0AAAAAZIjADgAAAAAyRGAHAAAAABkisAMAAACADBHYAQAAAECGCOwAAAAAIEMEdgAAAACQIQI7AAAAAMiQ2lu6AQAAAMBqqdxjY+U2wTxYh9yGb2XPz5dkQ56jlCJS2qLPkcAOAAAAMiJFxLSI+EO5YblcLnJrQoein7nc6kBhzc+qaqqcrgbj1rumijbkf9/Q9m3wOmyO7ZKfZ1U1FZYTa8ZndZ3XVbPe61+D+W/S11o1bVtnfYVtVOV0uVzkUorctGkRTz8dW5LADgAAADIixeqw7mdrfs+HDiUlJUVBUElJSVHAUtOa3JphJRWHl5u+ZE2AsV7LKClZPV1++jW1uXLrsLE11a5PROHneteU/73CuHwb1jb9Omuq2oblg7H8+tWwpmhZVT0n63huN8lrY31fP2t73sv9zMprI1KKKCuL3DPPrP59CxHYAQAAQIakiFi15mduzSPK/YxcLlaVG7c+NfkL2ac1gUfkcpEioqRc/apYHZKsrSa/jEJNfrpyP9OamthENVW1J9+OSu2pYU2RCuMK22At06+rJlehPRW3a/nxNakpWla5YZVqKs63BjWF8WuCt0J7SkoK0xfms741FcetpY0bVFNFeypNX9OaVasqvza2ADedAAAAAIAMEdgBAAAAQIYI7AAAAAAgQwR2AAAAAJAhAjsAAAAAyBCBHQAAAABkiMAOAAAAADJEYAcAAAAAGSKwAwAAAIAMEdgBAAAAQIYI7AAAAAAgQwR2AAAAAJAhAjsAAAAAyBCBHQAAAABkiMAOAAAAADJEYAcAAAAAGSKwAwAAAIAMEdgBAAAAQIYI7AAAAAAgQwR2AAAAAJAhAjsAAAAAyBCBHQAAAABkiMAOAAAAADJEYAcAAAAAGSKwAwAAAIAMEdgBAAAAQIYI7AAAAAAgQwR2AAAAAJAhAjsAAAAAyBCBHQAAAABkiMAOAAAAADJEYAcAAAAAGSKwAwAAAIAMEdgBAAAAQIYI7AAAAAAgQwR2AAAAAJAhAjsAAAAAyBCBHQAAAABkiMAOAAAAADJEYAcAAAAAGSKwAwAAAIAMEdgBAAAAQIYI7AAAAAAgQwR2AAAAAJAhAjsAAAAAyBCBHQAAAABkiMAOAAAAADJEYAcAAAAAGSKwAwAAAIAMEdgBAAAAQIYI7AAAAAAgQwR2AAAAAJAhAjsAAAAAyBCBHQAAAABkiMAOAAAAADJEYAcAAAAAGSKwAwAAAIAMEdgBAAAAQIYI7AAAAAAgQwR2AAAAAJAhAjsAAAAAyBCBHQAAAABkiMAOAAAAADJEYAcAAAAAGSKwAwAAAIAMEdgBAAAAQIYI7AAAAAAgQwR2AAAAAJAhAjsAAAAAyBCBHQAAAABkiMAOAAAAADJEYAcAAAAAGSKwAwAAAIAMEdgBAAAAQIYI7AAAAAAgQwR2AAAAAJAhAjsAAAAAyBCBHQAAAABkiMAOAAAAADJEYAcAAAAAGSKwAwAAAIAMEdgBAAAAQIYI7AAAAAAgQwR2AAAAAJAhAjsAAAAAyBCBHQAAAABkiMAOAAAAADJEYAcAAAAAGSKwAwAAAIAMEdgBAAAAQIYI7AAAAAAgQwR2AAAAAJAhAjsAAAAAyBCBHQAAAABkiMAOAAAAADJEYAcAAAAAGSKwAwAAAIAMEdgBAAAAQIYI7AAAAAAgQwR2AAAAAJAhAjsAAAAAyBCBHQAAAABkiMAOAAAAADJEYAcAAAAAGSKwAwAAAIAMEdgBAAAAQIYI7AAAAAAgQwR2AAAAAJAhAjsAAAAAyJDaW7oBAAB89bSdPz8iInK53OrH6j8Kv+dyuaK/C7/ncl9Mt2Z4Sb624nRraks2cF6FeZaUFE1Xsd258ssvKSkev57zKtoG5edVod3rGl/teq2lNv9zXdug0vgq5rs+26iods6ciI8/rtmLCAColsAOAID1dsSTTxZ+zxV+yRUPK/f3xgzb5POq6bBNOa91zD8L89roNkREfPppxJowFwDYcAI7AADWW9u3397STQAA+NpyDTsAAAAAyBCBHQAAAABkiMAOAAAAADJEYAcAAAAAGSKwAwAAAIAMEdgBAAAAQIYI7AAAAAAgQwR2AAAAAJAhAjsAAAAAyBCBHQAAAABkiMAOAAAAADJEYAcAAAAAGSKwAwAAAIAMEdgBAAAAQIYI7AAAAAAgQwR2AAAAAJAhAjsAAAAAyBCBHQAAAABkiMAOAAAAADJEYAcAAAAAGSKwAwAAAIAMEdgBAAAAQIYI7AAAAAAgQwR2AAAAAJAhAjsAAAAAyBCBHQAAAABkiMAOAAAAADJEYAcAAAAAGSKwAwAAAIAMEdgBAAAAQIYI7AAAAAAgQwR2AAAAAJAhAjsAAAAAyBCBHQAAAABkiMAOAAAAADJEYAcAAAAAGSKwAwAAAIAMEdgBAAAAQIYI7AAAAAAgQwR2AAAAAJAhAjsAAAAAyBCBHQAAAABkiMAOAAAAADJEYAcAAAAAGSKwAwAAAIAMEdgBAAAAQIYI7AAAAAAgQwR2AAAAAJAhAjsAAAAAyBCBHQAAAABkiMAOAAAAADJEYAcAAAAAGSKwAwAAAIAMEdgBAAAAQIYI7AAAAAAgQwR2AAAAAJAhAjsAAAAAyBCBHQAAAABkiMAOAAAAADJEYAcAAAAAGSKwAwAAAIAMEdgBAAAAQIYI7AAAAAAgQwR2AAAAAJAhAjsAAAAAyBCBHQAAAABkiMAOAAAAADJEYAcAAAAAGSKwAwAAAIAMEdgBAAAAQIYI7AAAAAAgQwR2AAAAAJAhAjsAAAAAyBCBHQAAAABkiMAOAAAAADJEYAcAAAAAGSKwAwAAAIAMEdgBAAAAQIYI7AAAAAAgQwR2AAAAAJAhAjsAAAAAyBCBHQAAAABkiMAOAAAAADJEYAcAAAAAGSKwAwAAAIAMEdgBAAAAQIYI7AAAAAAgQwR2AAAAAJAhAjsAAAAAyBCBHQAAAABkiMAOAAAAADJEYAcAAAAAGSKwAwAAAIAMEdgBAAAAQIYI7AAAAAAgQwR2AAAAAJAhAjsAAAAAyBCBHQAAAABkiMAOAAAAADJEYAcAAAAAGSKwAwAAAIAMEdgBAAAAQIYI7AAAAAAgQwR2AAAAAJAhAjsAAAAAyBCBHQAAAABkiMAOAAAAADJEYAcAAAAAGSKwAwAAAIAMqb2lGwAAAAB8oWTNI8UXR9mUREQu/0gpcrlcYVx+eFU1ufLDytek9MXwXC5yKUVJ+fqU1lkT5WpKqllWpPTFOlRVk1LldaiuHdW0p/wy1lZTNM/88vLT52vK11WsqWoZ5de14vaPiNyqVavbkX+sWhW5kpLi6VetisjlItbURMWaNdsocrnK0+bHpxS5kpLCz2pr8supqibfjjXLqtie8stYa82a4UU1JSWrt0kV069vTZXLqKI9FactyNekFFFSUlyzZjsVlr8FCewAAAAgI3IR0SvKnQ5XLviJWB1CxZq/c6sHFIbnyv1e3c8NHfdlTF+pZs361XRcoSY/bi01m63NX4VlrG3bbez0a8aVn6ZGdRXnuTmWUbGmimXkY73c009v8dBOYAcAAAAZkYuInhHRo/zAjBzx83WRW3fJV0/ua7lWW04G3m8COwAAAMiIXIWfUCMZCJjYtNx0AgAAAAAyRGAHAAAAABkisAMAAACADBHYAQAAAECGCOwAAAAAIEMEdgAAAACQIQI7AAAAAMgQgR0AAAAAZIjADgAAAAAyRGAHAAAAABkisAMAAACADBHYAQAAAECGCOwAAAAAIEMEdgAAAACQIQI7AAAAAMgQgR0AAAAAZIjADgAAAAAyRGAHAAAAABkisAMAAACADBHYAQAAAECG5FJKaUs3AgAAAABYzRF2AAAAAJAhAjsAAAAAyBCBHQAAAABkiMAOAAAAADJEYAcAAAAAGSKwAwAAAIAMEdgBAAAAQIYI7AAAAAAgQwR2AAAAAJAh/w/yu8ao+3tyCgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1600x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a demo image (100x100) with a gradient and a solid square in the center\n",
    "image = np.zeros((100, 100, 3), dtype=np.uint8)\n",
    "cv2.rectangle(image, (30, 30), (70, 70), (255, 255, 255), -1)  # White square\n",
    "for i in range(100):\n",
    "    image[:, i] = i * 2.55  # Gradient from black to white\n",
    "\n",
    "# Define background color\n",
    "background_color = (0, 0, 255)  # Red background\n",
    "\n",
    "# Perform clipping operations\n",
    "clipped_image_within, _, _ = safe_clip(image, 20, 20, 60, 60, background_color)\n",
    "clipped_image_edge, _, _ = safe_clip(image, 50, 50, 100, 100, background_color)\n",
    "clipped_image_outside, _, _ = safe_clip(image, -10, -10, 120, 120, background_color)\n",
    "\n",
    "# Setup matplotlib plots\n",
    "fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n",
    "axs[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "axs[0].set_title('Original Image')\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(cv2.cvtColor(clipped_image_within, cv2.COLOR_BGR2RGB))\n",
    "axs[1].set_title('Clipped Within Bounds')\n",
    "axs[1].axis('off')\n",
    "\n",
    "axs[2].imshow(cv2.cvtColor(clipped_image_edge, cv2.COLOR_BGR2RGB))\n",
    "axs[2].set_title('Clipped At Edge')\n",
    "axs[2].axis('off')\n",
    "\n",
    "axs[3].imshow(cv2.cvtColor(clipped_image_outside, cv2.COLOR_BGR2RGB))\n",
    "axs[3].set_title('Clipped Outside Bounds')\n",
    "axs[3].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5g--vkll2de"
   },
   "source": [
    "## Provide Unit Tests\n",
    "\n",
    "Unit testing is an essential facet of software engineering. Unit testing is necessary when a prompt generates your code. The following code shows how I converted the previous three examples into unit tests.\n",
    "\n",
    "Most software architects suggest you should not use an LLM to generate the unit tests because you must know what is being tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PFT-XSZ-l5U7"
   },
   "outputs": [],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "class TestSafeClip(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self.image = np.zeros((100, 100, 3), dtype=np.uint8)\n",
    "        cv2.rectangle(self.image, (30, 30), (70, 70), (255, 255, 255), -1)\n",
    "        for i in range(100):\n",
    "            self.image[:, i] = i * 2.55  # Gradient from black to white\n",
    "        self.background_color = (0, 0, 255)  # Blue background\n",
    "\n",
    "    def test_clip_within_bounds(self):\n",
    "        clipped_image, x_off, y_off = safe_clip(self.image, 20, 20, 60, 60, self.background_color)\n",
    "        self.assertEqual(clipped_image.shape, (60, 60, 3))\n",
    "        self.assertEqual((x_off, y_off), (0, 0))\n",
    "        self.assertTrue((clipped_image[0, 0] != self.background_color).all())\n",
    "\n",
    "    def test_clip_at_edge(self):\n",
    "        clipped_image, x_off, y_off = safe_clip(self.image, 50, 50, 100, 100, self.background_color)\n",
    "        self.assertEqual(clipped_image.shape, (100, 100, 3))\n",
    "        self.assertEqual((x_off, y_off), (0, 0))\n",
    "        self.assertTrue((clipped_image[0, 0] == [127, 127, 127]).all())\n",
    "\n",
    "    def test_clip_outside_bounds(self):\n",
    "        clipped_image, x_off, y_off = safe_clip(self.image, -10, -10, 120, 120, self.background_color)\n",
    "        self.assertEqual(clipped_image.shape, (120, 120, 3))\n",
    "        self.assertEqual((x_off, y_off), (10, 10))\n",
    "        self.assertTrue((clipped_image[10, 10] == [0, 0, 0]).all())\n",
    "\n",
    "test = TestSafeClip()\n",
    "test.setUp()\n",
    "test.test_clip_within_bounds()\n",
    "test.test_clip_at_edge()\n",
    "test.test_clip_outside_bounds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
