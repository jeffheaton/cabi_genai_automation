{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whjsJasuhstV"
   },
   "source": [
    "# Introduction to Automation with LangChain, Generative AI, and Python\n",
    "**2.9: Persisting Langchain Memory**\n",
    "* Instructor: [Jeff Heaton](https://youtube.com/@HeatonResearch), WUSTL Center for Analytics and Business Insight (CABI), [Washington University in St. Louis](https://olin.wustl.edu/faculty-and-research/research-centers/center-for-analytics-and-business-insight/index.php)\n",
    "* For more information visit the [class website](https://github.com/jeffheaton/cabi_genai_automation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pC9A-LaYhsta"
   },
   "source": [
    "In this section, we delve into the creation of an innovative utility class designed for managing chat interactions—aptly named ChatBot. This class stands as a cornerstone for applications that require robust handling of chat history, including features to load and save these interactions, as well as capabilities to undo or regenerate outputs. The architecture of ChatBot integrates advanced language models with structured templates to facilitate interactive conversations, ensuring a seamless and dynamic user experience.\n",
    "\n",
    "The core functionality of ChatBot revolves around its sophisticated integration of components from the langchain ecosystem. It utilizes a large language model for generating chat responses and another for summarizing conversations, complemented by a template that structures each interaction. Key features include maintaining an editable conversation history, implementing undo and regenerate operations for greater control over chat flows, and mechanisms to persist conversation states, enhancing the utility and flexibility of the chat interface. As we explore ChatBot, we will uncover how each component contributes to its overall capability to manage complex conversational contexts effectively.\n",
    "\n",
    "The code for this class follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TMF-rtxgRAea"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain_core.prompts.chat import PromptTemplate\n",
    "from IPython.display import display_markdown\n",
    "import pickle\n",
    "\n",
    "DEFAULT_TEMPLATE = \"\"\"You are a helpful assistant. Format answers with markdown.\n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "\n",
    "MODEL = 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "\n",
    "class ChatBot:\n",
    "    def __init__(self, llm_chat, llm_summary, template):\n",
    "        \"\"\"\n",
    "        Initializes the ChatBot with language models and a template for conversation.\n",
    "\n",
    "        :param llm_chat: A large language model for handling chat responses.\n",
    "        :param llm_summary: A large language model for summarizing conversations.\n",
    "        :param template: A string template defining the conversation structure.\n",
    "        \"\"\"\n",
    "        self.llm_chat = llm_chat\n",
    "        self.llm_summary = llm_summary\n",
    "        self.template = template\n",
    "        self.prompt_template = PromptTemplate(input_variables=[\"history\", \"input\"], template=self.template)\n",
    "\n",
    "        # Initialize memory and conversation chain\n",
    "        self.memory = ConversationSummaryMemory(llm=self.llm_summary)\n",
    "        self.conversation = ConversationChain(\n",
    "            prompt=self.prompt_template,\n",
    "            llm=self.llm_chat,\n",
    "            memory=self.memory,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        self.history = []\n",
    "\n",
    "    def converse(self, prompt):\n",
    "        \"\"\"\n",
    "        Processes a conversation prompt and updates the internal history and memory.\n",
    "\n",
    "        :param prompt: The input prompt from the user.\n",
    "        :return: The generated response from the language model.\n",
    "        \"\"\"\n",
    "        self.history.append([self.memory.buffer, prompt])\n",
    "        output = self.conversation.invoke(prompt)\n",
    "        return output['response']\n",
    "\n",
    "    def chat(self, prompt):\n",
    "        \"\"\"\n",
    "        Handles the full cycle of receiving a prompt, processing it, and displaying the result.\n",
    "\n",
    "        :param prompt: The input prompt from the user.\n",
    "        \"\"\"\n",
    "        print(f\"Human: {prompt}\")\n",
    "        output = self.converse(prompt)\n",
    "        display_markdown(output, raw=True)\n",
    "\n",
    "    def print_memory(self):\n",
    "        \"\"\"\n",
    "        Displays the current state of the conversation memory.\n",
    "        \"\"\"\n",
    "        print(\"**Memory:\")\n",
    "        print(self.memory.buffer)\n",
    "\n",
    "    def clear_memory(self):\n",
    "        \"\"\"\n",
    "        Clears the conversation memory.\n",
    "        \"\"\"\n",
    "        self.memory.clear()\n",
    "\n",
    "    def undo(self):\n",
    "        \"\"\"\n",
    "        Reverts the conversation memory to the state before the last interaction.\n",
    "        \"\"\"\n",
    "        if len(self.history) > 0:\n",
    "            self.memory.buffer = self.history.pop()[0]\n",
    "        else:\n",
    "            print(\"Nothing to undo.\")\n",
    "\n",
    "    def regenerate(self):\n",
    "        \"\"\"\n",
    "        Re-executes the last undone interaction, effectively redoing an undo operation.\n",
    "        \"\"\"\n",
    "        if len(self.history) > 0:\n",
    "            self.memory.buffer, prompt = self.history.pop()\n",
    "            self.chat(prompt)\n",
    "        else:\n",
    "            print(\"Nothing to regenerate.\")\n",
    "\n",
    "    def save_history(self, file_path):\n",
    "        \"\"\"\n",
    "        Saves the conversation history to a file using pickle.\n",
    "\n",
    "        :param file_path: The file path where the history should be saved.\n",
    "        \"\"\"\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(self.history, f)\n",
    "\n",
    "    def load_history(self, file_path):\n",
    "        \"\"\"\n",
    "        Loads the conversation history from a file using pickle.\n",
    "\n",
    "        :param file_path: The file path from which to load the history.\n",
    "        \"\"\"\n",
    "        with open(file_path, 'rb') as f:\n",
    "            self.history = pickle.load(f)\n",
    "            # Optionally reset the memory based on the last saved state\n",
    "            if self.history:\n",
    "                self.memory.buffer = self.history[-1][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zJA-AF8vBtW"
   },
   "source": [
    "## Testing the Chat Bot\n",
    "Before we see how this class was constructed, lets see how you can use it. The following shows a simple chat interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "tXJAk_dAtuFb",
    "outputId": "eaf8236d-6f3d-4ad9-bc0f-bef02873364a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hello, my name is Jeff.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Nice to meet you, Jeff! I'm an AI assistant created by Anthropic. I'm here to help with any questions or tasks you may have. Please let me know if there's anything I can assist with.\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: I like coffee.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Great, I'm glad you enjoy coffee! Here are a few thoughts on coffee in markdown format:\n",
       "\n",
       "### Coffee Facts\n",
       "\n",
       "- **Origin**: Coffee is believed to have originated in the forests of Ethiopia, where coffee trees grew wild.\n",
       "\n",
       "- **Popular Varieties**: Some of the most popular coffee varieties include Arabica, Robusta, Liberica, and Excelsa.\n",
       "\n",
       "- **Caffeine Content**: A typical 8 oz cup of brewed coffee contains around 95mg of caffeine.\n",
       "\n",
       "- **Preparation Methods**: Common ways to brew coffee include drip brewing, French press, pour over, espresso, and cold brew.\n",
       "\n",
       "### Coffee Trivia\n",
       "\n",
       "- The word \"coffee\" comes from the Arabic term \"qahwah\" which referred to a type of wine.\n",
       "\n",
       "- Finland has the highest per capita coffee consumption in the world.\n",
       "\n",
       "- Coffee is one of the most traded commodities in the world after oil.\n",
       "\n",
       "Let me know if you have any other coffee-related questions! I'm always happy to discuss this beloved beverage."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: What is my name.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Based on the conversation, your name is Jeff.\n",
       "\n",
       "```\n",
       "Jeff: *introduces themselves as Jeff*\n",
       "AI: *greets Jeff*\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Do I like coffee?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Based on our conversation, you did mention that you like coffee. Specifically, you said \"I like coffee\" after introducing yourself as Jeff.\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL = 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "\n",
    "# Initialize bedrock, use built in role\n",
    "llm = ChatBedrock(\n",
    "        model_id=MODEL,\n",
    "        model_kwargs={\"temperature\": 0.1},\n",
    ")\n",
    "\n",
    "c = ChatBot(llm, llm, DEFAULT_TEMPLATE)\n",
    "\n",
    "c.chat(\"Hello, my name is Jeff.\")\n",
    "c.chat(\"I like coffee.\")\n",
    "c.chat(\"What is my name.\")\n",
    "c.chat(\"Do I like coffee?\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEut99OTt_AG"
   },
   "source": [
    "## Load and Save Chat Memory\n",
    "\n",
    "The chat bot allows the complete chat history and memory to be saved and loaded from a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Z09iSHYvt8is",
    "outputId": "4ece6ca7-776f-49f7-ecea-0e7e535e04b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hello, my name is Jeff.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Nice to meet you, Jeff! I'm an AI assistant created by Anthropic. I'm here to help with any questions or tasks you may have. Please let me know if there's anything I can assist with.\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: I like coffee.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Great, I'm glad you enjoy coffee! Here are a few thoughts on coffee in markdown format:\n",
       "\n",
       "### Coffee Facts\n",
       "\n",
       "- **Origin**: Coffee is believed to have originated in the forests of Ethiopia, where coffee trees grew wild.\n",
       "\n",
       "- **Popular Varieties**: Some of the most popular coffee varieties include Arabica, Robusta, Liberica, and Excelsa.\n",
       "\n",
       "- **Caffeine Content**: A typical 8 oz cup of brewed coffee contains around 95mg of caffeine.\n",
       "\n",
       "- **Preparation Methods**: Common ways to brew coffee include drip brewing, French press, pour over, espresso, and cold brew.\n",
       "\n",
       "### Coffee Trivia\n",
       "\n",
       "- The word \"coffee\" comes from the Arabic term \"qahwah\" which referred to a type of wine.\n",
       "\n",
       "- Finland has the highest per capita coffee consumption in the world.\n",
       "\n",
       "- Coffee is one of the most traded commodities in the world after oil.\n",
       "\n",
       "Let me know if you have any other coffee-related questions! I'd be happy to discuss further."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: What is my name.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Based on the conversation, your name is Jeff."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Do I like coffee?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Based on the conversation, you stated that you like coffee:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize bedrock, use built in role\n",
    "llm = ChatBedrock(\n",
    "        model_id=MODEL,\n",
    "        model_kwargs={\"temperature\": 0.1},\n",
    ")\n",
    "\n",
    "c = ChatBot(llm, llm, DEFAULT_TEMPLATE)\n",
    "c.chat(\"Hello, my name is Jeff.\")\n",
    "c.chat(\"I like coffee.\")\n",
    "c.chat(\"What is my name.\")\n",
    "c.chat(\"Do I like coffee?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ScF3OysvTWk"
   },
   "source": [
    "We now save the chat memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "pllixtJUuDP0"
   },
   "outputs": [],
   "source": [
    "c.save_history('history.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUvlZe3FvW-0"
   },
   "source": [
    "You can now reload the chat memory; the bot should remember the discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 64
    },
    "id": "O3O2kcEzuFvF",
    "outputId": "eb72fde1-1619-4c13-d329-21781e5ed96a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: What is my name?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Based on the conversation, your name is **Jeff**."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = ChatBot(llm, llm, DEFAULT_TEMPLATE)\n",
    "c.load_history('history.pkl')\n",
    "c.chat(\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ClPhLkGldhPt"
   },
   "source": [
    "## Undoing and Regenerating the Chat\n",
    "\n",
    "The chatbot allows us to undo parts of the conversation, and it forgets. We can also regenerate outputs to get a better response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "ydaqwgRiH4D6",
    "outputId": "11aaa405-6a00-4a82-e6d8-bcdf9adb6f45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hello, my name is Jeff.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Nice to meet you, Jeff! I'm an AI assistant created by Anthropic. I'm here to help with any questions or tasks you may have. Please let me know if there's anything I can assist with.\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: I like coffee.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Great, I'm glad you like coffee! Here are a few thoughts on coffee in markdown format:\n",
       "\n",
       "### Coffee Facts\n",
       "\n",
       "- **Origin**: Coffee is believed to have originated in the forests of Ethiopia, where coffee trees grew wild.\n",
       "\n",
       "- **Popular Varieties**: Some of the most popular coffee varieties include Arabica, Robusta, Liberica, and Excelsa.\n",
       "\n",
       "- **Caffeine Content**: A typical 8 oz cup of brewed coffee contains around 95mg of caffeine.\n",
       "\n",
       "- **Preparation Methods**: Common ways to brew coffee include drip brewing, French press, pour over, espresso, and cold brew.\n",
       "\n",
       "### Coffee Trivia\n",
       "\n",
       "- The word \"coffee\" comes from the Arabic term \"qahwah\" which referred to a type of wine.\n",
       "\n",
       "- Finland has the highest per capita coffee consumption in the world.\n",
       "\n",
       "- Coffee is one of the most traded commodities in the world after oil.\n",
       "\n",
       "Let me know if you have any other coffee-related questions! I'm always happy to discuss this beloved beverage."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: What is my name.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Your name is Jeff, based on your introduction at the start of our conversation.\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Do I like coffee?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Unfortunately, I don't have enough information to know whether you like coffee or not. As an AI assistant, I don't have personal knowledge about your preferences unless you provide that information to me.\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Do I like coffee?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Unfortunately, I don't have enough information to know whether you like coffee or not. As an AI assistant without personal knowledge about you, I can only respond based on what you directly tell me.\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize bedrock, use built in role\n",
    "llm = ChatBedrock(\n",
    "        model_id=MODEL,\n",
    "        model_kwargs={\"temperature\": 0.1},\n",
    ")\n",
    "\n",
    "c = ChatBot(llm, llm, DEFAULT_TEMPLATE)\n",
    "\n",
    "c.chat(\"Hello, my name is Jeff.\")\n",
    "c.chat(\"I like coffee.\")\n",
    "c.undo()\n",
    "c.chat(\"What is my name.\")\n",
    "c.chat(\"Do I like coffee?\")\n",
    "c.regenerate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KrNDYZ5rw1e_"
   },
   "source": [
    "## Implementing the Chatbot\n",
    "\n",
    "In this section, we delve into the architecture of a sophisticated chatbot built using the LangChain and Bedrock libraries, encapsulated within the ChatBot class. The ChatBot class leverages two language models and a structured conversation template to engage users in a dynamic conversational flow.\n",
    "\n",
    "The class initiates by defining its basic components: llm_chat and llm_summary are large language models used for chat responses and conversation summarization, respectively. The template parameter defines the conversation's structure, guiding how interactions are formatted and presented. This template incorporates markdown formatting and placeholders for the conversation history and the latest user input, facilitating a clear and structured dialogue presentation.\n",
    "\n",
    "Upon instantiation, the ChatBot initializes various components. It constructs a PromptTemplate, which prepares the structure for input variables and the conversation template. The ConversationSummaryMemory, initialized with the llm_summary, acts as a dynamic storage for conversation excerpts, aiding in recalling context or summarizing past dialogues. This memory component is crucial for maintaining conversation continuity, especially in sessions that might span multiple interactions.\n",
    "\n",
    "The ConversationChain is another pivotal element, combining the prompt template with the llm_chat model to process and respond to user inputs. The chain's verbose mode is set to False to streamline output without extraneous system messages.\n",
    "\n",
    "Interaction with the ChatBot is primarily through the chat method, where users provide a prompt, and the bot displays the response after processing. Internally, the converse method updates the conversation history and uses the conversation chain to generate a response. This method's utility lies in its ability to append each interaction to the history log, ensuring all discourse components are retained for future reference or undo actions.\n",
    "\n",
    "Memory management functions like print_memory, clear_memory, and undo provide users and developers with tools to view, reset, or revert the conversation state, thus offering flexibility in managing the dialogue flow and content. Additional functionalities to save and load conversation history are provided through save_history and load_history, utilizing Python’s pickle module for object serialization.\n",
    "\n",
    "This class structure not only facilitates robust conversation handling and memory management but also showcases the integration of advanced language models in practical applications, demonstrating the potential of AI in enhancing interactive software solutions. Through such a detailed setup, ChatBot serves as a comprehensive framework for building interactive, memory-aware chatbot systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Chat Session\n",
    "\n",
    "The following code implements an interactive chat session with memory and rollback/regenerate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human>>>  /redo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing to regenerate.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human>>>  /undo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing to undo.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human>>>  I like coffee\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<span style='color: blue;'>AI>>> ```\n",
       "I'm glad you enjoy coffee! Coffee is a beloved beverage around the world, enjoyed for its rich aroma, flavor, and energizing effects from the caffeine. There are many different varieties and ways to prepare coffee, from classic drip coffee to espresso-based drinks like lattes and cappuccinos. Coffee can be a delightful morning ritual or an afternoon pick-me-up.\n",
       "```</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human>>>  /redo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: I like coffee\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "That's great! Coffee is a beloved beverage enjoyed by many people around the world. Here are a few thoughts on coffee:\n",
       "\n",
       "- Coffee contains caffeine, which is a stimulant that can help increase alertness and focus.\n",
       "\n",
       "- There are many different varieties of coffee beans, each with its own unique flavor profile. Popular types include Arabica, Robusta, Kona, and Colombian.\n",
       "\n",
       "- Coffee can be prepared in various ways, such as drip brewing, French press, espresso, and pour-over methods.\n",
       "\n",
       "- In addition to the classic black coffee, there are many coffee-based drinks like lattes, cappuccinos, and mochas that incorporate milk, flavored syrups, or other ingredients.\n",
       "\n",
       "- Coffee shops and cafes have become popular gathering spots for people to socialize, work, or simply enjoy a good cup of coffee.\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human>>>  /undo\n",
      "Human>>>  /undo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing to undo.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human>>>  /redo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing to regenerate.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m c \u001b[38;5;241m=\u001b[39m ChatBot(llm, llm, DEFAULT_TEMPLATE)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 6\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHuman>>> \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prompt[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      8\u001b[0m         cmd \u001b[38;5;241m=\u001b[39m prompt[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mlower()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown, HTML\n",
    "\n",
    "c = ChatBot(llm, llm, DEFAULT_TEMPLATE)\n",
    "\n",
    "while True:\n",
    "    prompt = input(\"Human>>> \").strip()\n",
    "    if prompt[0] == \"/\":\n",
    "        cmd = prompt[1:].strip().lower()\n",
    "        if cmd == 'bye':\n",
    "            break\n",
    "        elif cmd == 'undo':\n",
    "            c.undo()\n",
    "        elif cmd == 'redo':\n",
    "            c.regenerate()\n",
    "        elif cmd == 'dump':\n",
    "            c.print_memory()\n",
    "        else:\n",
    "            display(HTML(f\"<span style='color: red;'>Unknown command: {cmd}</span>\"))\n",
    "            \n",
    "    else:\n",
    "        response = c.converse(prompt)\n",
    "        markdown_text = f\"<span style='color: blue;'>AI>>> {response}</span>\"\n",
    "        display(Markdown(markdown_text))\n",
    "\n",
    "display(HTML(\"<span style='color: red;'>Chat done.</span>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
