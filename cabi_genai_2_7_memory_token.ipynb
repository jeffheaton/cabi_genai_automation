{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whjsJasuhstV"
   },
   "source": [
    "# Introduction to Automation with LangChain, Generative AI, and Python\n",
    "**2.7: Conversation Token Buffer Memory**\n",
    "* Instructor: [Jeff Heaton](https://youtube.com/@HeatonResearch), WUSTL Center for Analytics and Business Insight (CABI), [Washington University in St. Louis](https://olin.wustl.edu/faculty-and-research/research-centers/center-for-analytics-and-business-insight/index.php)\n",
    "* For more information visit the [class website](https://github.com/jeffheaton/cabi_genai_automation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pC9A-LaYhsta"
   },
   "source": [
    "We previously saw that ConversationBufferWindowMemory can remember the last **k** messages exchanged between the AI and human chatter. Basing the memory on the last number of chat lines has one serious limitation. The underlying LLM limits the chat memory amount based on the context window size, which is measured in tokens, not lines.\n",
    "\n",
    "In this part, we will see how to use the ConversationTokenBufferMemory. It works almost exactly like the ConversationBufferWindowMemory, except that you specify how many tokens it should keep from the conversation, not how many lines. This technique lets you decide how much of the context window you wish to devote to memory. Remember that the context window must also hold the input prompt and output from the LLM; therefore, some planning is required.\n",
    "\n",
    "The following code shows how to use a ConversationTokenBufferMemory as the memory of the chat chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TMF-rtxgRAea"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain_core.prompts.chat import PromptTemplate\n",
    "from IPython.display import display_markdown\n",
    "\n",
    "MODEL = 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "TEMPLATE = \"\"\"You are a helpful assistant. Format answers with markdown.\n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "PROMPT_TEMPLATE = PromptTemplate(input_variables=[\"history\", \"input\"], template=TEMPLATE)\n",
    "\n",
    "def begin_conversation(summary_llm):\n",
    "    # Initialize bedrock, use built in role\n",
    "    llm = ChatBedrock(\n",
    "        model_id=MODEL,\n",
    "        model_kwargs={\"temperature\": 0.1},\n",
    "    )\n",
    "\n",
    "    # Initialize memory and conversation\n",
    "    memory = ConversationTokenBufferMemory(llm=summary_llm,max_token_limit=2048)\n",
    "    conversation = ConversationChain(\n",
    "        prompt=PROMPT_TEMPLATE,\n",
    "        llm=llm,\n",
    "        memory=memory,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    return conversation\n",
    "\n",
    "def converse(conversation, prompt):\n",
    "    print(f\"***Human: {prompt}\")\n",
    "    output = conversation.invoke(prompt)\n",
    "    return output['response']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ClPhLkGldhPt"
   },
   "source": [
    "We can now carry on a simple conversation with the LLM, using LangChain to track the conversation memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 93
    },
    "id": "ydaqwgRiH4D6",
    "outputId": "a2669f58-ba12-4898-80b4-80796647dee0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: Hello, what is my name?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Unfortunately, I don't actually know your name. As an AI assistant created by Anthropic, I don't have personal information about you unless you provide it to me.\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: Oh sorry, my name is Jeff.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Nice to meet you Jeff! I've updated my knowledge that your name is Jeff. Please let me know if you have any other questions I can assist you with.\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: What is my name?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Your name is Jeff.\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize bedrock, use built in role\n",
    "llm = ChatBedrock(\n",
    "    model_id=MODEL,\n",
    "    model_kwargs={\"temperature\": 0.7},\n",
    ")\n",
    "\n",
    "conversation = begin_conversation(llm)\n",
    "output = converse(conversation, \"Hello, what is my name?\")\n",
    "display_markdown(output,raw=True)\n",
    "output = converse(conversation, \"Oh sorry, my name is Jeff.\")\n",
    "display_markdown(output,raw=True)\n",
    "output = converse(conversation, \"What is my name?\")\n",
    "display_markdown(output,raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ulYUrfVcnlgF"
   },
   "source": [
    "## Conversing with the LLM in Markdown\n",
    "\n",
    "Just as before, we can request that the LLM output be in mardown. This allows code and tables to be represented clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MHL6Ik8IM2PA"
   },
   "outputs": [],
   "source": [
    "def chat(conversation, prompt):\n",
    "  output = converse(conversation, prompt)\n",
    "  display_markdown(output,raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FvzsYl3Qplac"
   },
   "source": [
    "The provided code sequence demonstrates a conversation between a human user and a Large Language Model (LLM), making use of the chat function to interactively manage the conversation and display responses in Markdown format. This approach allows for a dynamic and contextually aware chat, while also enhancing the visual and structural presentation of the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "PtLDak7TM_FU",
    "outputId": "a92c843d-a71d-433f-9caf-8d9df77998dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: What is my name?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Unfortunately, I don't actually know your name. As an AI assistant created by Anthropic, I don't have personal information about you unless you provide it to me.\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: Okay, then let me introduce myself, my name is Jeff\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Nice to meet you, Jeff! I've updated my knowledge that your name is Jeff. Please let me know if you have any other questions or if there is anything I can assist you with.\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: What is my name?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Your name is Jeff.\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: Give me a table of the 5 most populus cities with population and country.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "| City | Population | Country |\n",
       "| --- | --- | --- |\n",
       "| Tokyo | 37,435,191 | Japan |\n",
       "| Delhi | 29,398,000 | India |\n",
       "| Mexico City | 21,581,000 | Mexico |\n",
       "| SÃ£o Paulo | 21,846,000 | Brazil |\n",
       "| Mumbai | 20,961,000 | India |\n",
       "```\n",
       "\n",
       "This table shows the 5 most populous cities in the world, along with their population figures and the countries they are located in. The data is based on the latest available estimates from reputable sources."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conversation = begin_conversation(llm)\n",
    "chat(conversation, \"What is my name?\")\n",
    "chat(conversation, \"Okay, then let me introduce myself, my name is Jeff\")\n",
    "chat(conversation, \"What is my name?\")\n",
    "chat(conversation, \"Give me a table of the 5 most populus cities with population and country.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GeY-9YSOno_t"
   },
   "source": [
    "## Constraining the Conversation with a System Prompt\n",
    "\n",
    "You can use the system prompt to constrain the conversation to a specific topic. Here, we provide a simple agent that will only discuss life insurance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "id": "NyGpLJmWjGNq",
    "outputId": "4462dc2e-8aae-4bf1-f58f-3ee6f6384eb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: What is my name?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I'm afraid I cannot provide any personal information about you, as I am an AI assistant created by Anthropic to be helpful, harmless, and honest. However, I'd be happy to answer any questions you have about life insurance. Please feel free to ask, and I will respond in a markdown format."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: Okay, then let me introduce myself, my name is Jeff\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Thank you for introducing yourself, Jeff. As an AI assistant focused on providing information about life insurance, I don't have the capability to store or recall personal details about you or other users. However, I'm happy to answer any questions you may have related to life insurance policies, coverage, premiums, or any other relevant topics. Please feel free to ask, and I'll do my best to provide helpful and accurate information in a markdown format.\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: What is my name?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "As an AI assistant, I do not actually have any information about your name or personal details. My role is to provide helpful information about life insurance topics, rather than storing or recalling personal data about users. If you have any questions related to life insurance, I'll be happy to assist you. However, I cannot provide or confirm any personal information.\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: What is your favorite programming language?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "As an AI assistant focused solely on providing information about life insurance, I do not have personal preferences or knowledge about programming languages. My role is to helpfully answer questions related to life insurance topics, such as policy types, coverage options, premiums, and claims processes. If you have any questions within that scope, I'll be glad to assist you. However, I cannot engage in discussions or provide information outside of the life insurance domain.\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: What is the difference between a term and whole life policy?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "The main difference between term life insurance and whole life insurance lies in the coverage period and the cash value component.\n",
       "\n",
       "Term Life Insurance:\n",
       "- Provides coverage for a specific term or period of time (e.g., 10, 20, or 30 years)\n",
       "- Offers only a death benefit, with no cash value component\n",
       "- Premiums are typically lower than whole life insurance\n",
       "- Coverage expires at the end of the term unless the policy is renewed\n",
       "\n",
       "Whole Life Insurance:\n",
       "- Provides coverage for the entire lifetime of the insured person\n",
       "- Builds up a cash value component that can be borrowed against or withdrawn\n",
       "- Premiums are generally higher than term life insurance\n",
       "- Premiums remain level for the life of the policy\n",
       "- Offers a guaranteed death benefit as long as premiums are paid\n",
       "\n",
       "In summary, term life insurance provides temporary coverage at a lower cost, while whole life insurance offers lifelong protection and a cash value component, but with higher premiums.\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain_core.prompts.chat import PromptTemplate\n",
    "from IPython.display import display_markdown\n",
    "\n",
    "def begin_conversation_insurance(summary_llm):\n",
    "    TEMPLATE = \"\"\"You are a helpful agent to answer questions about life insurance. Do not talk\n",
    "    about anything else with users. . Format answers with markdown.\n",
    "\n",
    "    Current conversation:\n",
    "    {history}\n",
    "    Human: {input}\n",
    "    AI:\"\"\"\n",
    "    PROMPT_TEMPLATE = PromptTemplate(input_variables=[\"history\", \"input\"], template=TEMPLATE)\n",
    "\n",
    "  # Initialize bedrock, use built in role\n",
    "    llm = ChatBedrock(\n",
    "        model_id=MODEL,\n",
    "        model_kwargs={\"temperature\": 0.1},\n",
    "    )\n",
    "\n",
    "    # Initialize memory and conversation\n",
    "    memory = ConversationTokenBufferMemory(llm=summary_llm,max_token_limit=2048)\n",
    "    conversation = ConversationChain(\n",
    "        prompt=PROMPT_TEMPLATE,\n",
    "        llm=llm,\n",
    "        memory=memory,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    return conversation\n",
    "\n",
    "conversation = begin_conversation_insurance(llm)\n",
    "chat(conversation, \"What is my name?\")\n",
    "chat(conversation, \"Okay, then let me introduce myself, my name is Jeff\")\n",
    "chat(conversation, \"What is my name?\")\n",
    "chat(conversation, \"What is your favorite programming language?\")\n",
    "chat(conversation, \"What is the difference between a term and whole life policy?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgwRMwnlH5Ou"
   },
   "source": [
    "##Examining the Conversation Memory\n",
    "\n",
    "We can quickly look inside the memory of the LangChain-managed chat memory and see our conversation memory with the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WZDN67SOHkNo",
    "outputId": "74ddf9a8-9580-48e4-c9fc-13dd5225c3f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': \"Human: What is my name?\\nAI: I'm afraid I cannot provide any personal information about you, as I am an AI assistant created by Anthropic to be helpful, harmless, and honest. However, I'd be happy to answer any questions you have about life insurance. Please feel free to ask, and I will respond in a markdown format.\\nHuman: Okay, then let me introduce myself, my name is Jeff\\nAI: ```\\nThank you for introducing yourself, Jeff. As an AI assistant focused on providing information about life insurance, I don't have the capability to store or recall personal details about you or other users. However, I'm happy to answer any questions you may have related to life insurance policies, coverage, premiums, or any other relevant topics. Please feel free to ask, and I'll do my best to provide helpful and accurate information in a markdown format.\\n```\\nHuman: What is my name?\\nAI: ```\\nAs an AI assistant, I do not actually have any information about your name or personal details. My role is to provide helpful information about life insurance topics, rather than storing or recalling personal data about users. If you have any questions related to life insurance, I'll be happy to assist you. However, I cannot provide or confirm any personal information.\\n```\\nHuman: What is your favorite programming language?\\nAI: ```\\nAs an AI assistant focused solely on providing information about life insurance, I do not have personal preferences or knowledge about programming languages. My role is to helpfully answer questions related to life insurance topics, such as policy types, coverage options, premiums, and claims processes. If you have any questions within that scope, I'll be glad to assist you. However, I cannot engage in discussions or provide information outside of the life insurance domain.\\n```\\nHuman: What is the difference between a term and whole life policy?\\nAI: ```markdown\\nThe main difference between term life insurance and whole life insurance lies in the coverage period and the cash value component.\\n\\nTerm Life Insurance:\\n- Provides coverage for a specific term or period of time (e.g., 10, 20, or 30 years)\\n- Offers only a death benefit, with no cash value component\\n- Premiums are typically lower than whole life insurance\\n- Coverage expires at the end of the term unless the policy is renewed\\n\\nWhole Life Insurance:\\n- Provides coverage for the entire lifetime of the insured person\\n- Builds up a cash value component that can be borrowed against or withdrawn\\n- Premiums are generally higher than term life insurance\\n- Premiums remain level for the life of the policy\\n- Offers a guaranteed death benefit as long as premiums are paid\\n\\nIn summary, term life insurance provides temporary coverage at a lower cost, while whole life insurance offers lifelong protection and a cash value component, but with higher premiums.\\n```\"}\n"
     ]
    }
   ],
   "source": [
    "print(conversation.memory.load_memory_variables({}))\n",
    "#conversation.memory.chat_memory.max_token_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 64
    },
    "id": "yrwPUYU2fQRw",
    "outputId": "2ff7cbe5-f041-4a1c-9ab4-b732bd20bf59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: What type of policy did I ask you about?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "You did not ask me about a specific type of life insurance policy. In our conversation, you introduced yourself as Jeff, but I clarified that as an AI assistant, I do not actually store or recall personal details about users.\n",
       "\n",
       "Then, you asked me about the difference between term life insurance and whole life insurance policies. I provided a detailed explanation comparing the two types of policies, covering aspects such as coverage period, cash value component, premiums, and death benefits.\n",
       "\n",
       "However, you did not specify which type of policy you were inquiring about or provide any personal details that would allow me to determine the type of policy you might be interested in or have. As an AI assistant focused solely on providing information about life insurance, I can only respond based on the questions asked and cannot make assumptions about your personal circumstances or preferences.\n",
       "\n",
       "If you have a specific question about a particular type of life insurance policy or your personal situation, please feel free to ask, and I will do my best to provide relevant information within the scope of my knowledge and capabilities.\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat(conversation, \"What type of policy did I ask you about?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aW0TPWRBJ2w2"
   },
   "source": [
    "## Overloading the Memory\n",
    "\n",
    "When the conversation memory becomes full, the chatbot will begin to forget. For the ConversationTokenBufferMemory memory type, the oldest history will first be lost; there is no notion of importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "d-a2iUpTJIYn",
    "outputId": "f82dfce7-0332-4024-ffec-e3c0068b952f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: Okay, then let me introduce myself, my name is Jeff\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Nice to meet you, Jeff! I'm an AI assistant created by Anthropic. I'm here to help with any questions or tasks you may have. Please let me know if there's anything specific I can assist you with.\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: You have ONE JOB! Remember that my favorite color is blue.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Got it, Jeff! I'll make sure to remember that your favorite color is blue.\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: Do you remember my name?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Yes, I remember that your name is Jeff.\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: Do you remember my favorite color?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Yes, I remember that your favorite color is blue.\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: You need to remember fact #0, which is d95f5e27-5cd9-4444-a106-ca9a2a8fb856\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Okay, got it. I will remember that fact #0 is d95f5e27-5cd9-4444-a106-ca9a2a8fb856.\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: You need to remember fact #1, which is e43f40f3-267a-44ca-9be4-d9f19a04634d\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Understood. I will remember the following facts:\n",
       "\n",
       "Fact #0: d95f5e27-5cd9-4444-a106-ca9a2a8fb856\n",
       "Fact #1: e43f40f3-267a-44ca-9be4-d9f19a04634d\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: You need to remember fact #2, which is e481ec91-2d11-4b4e-a457-b12803296c27\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Got it, here are the facts I'm remembering:\n",
       "\n",
       "Fact #0: d95f5e27-5cd9-4444-a106-ca9a2a8fb856\n",
       "Fact #1: e43f40f3-267a-44ca-9be4-d9f19a04634d \n",
       "Fact #2: e481ec91-2d11-4b4e-a457-b12803296c27\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: You need to remember fact #3, which is 07691b34-3497-4992-a370-97d67ec38939\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Okay, I've updated the list of facts I'm remembering:\n",
       "\n",
       "Fact #0: d95f5e27-5cd9-4444-a106-ca9a2a8fb856\n",
       "Fact #1: e43f40f3-267a-44ca-9be4-d9f19a04634d\n",
       "Fact #2: e481ec91-2d11-4b4e-a457-b12803296c27\n",
       "Fact #3: 07691b34-3497-4992-a370-97d67ec38939\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: You need to remember fact #4, which is 6ef030e6-a76e-4bd1-9645-6e46156c4a0a\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Got it, here is the updated list of facts I'm remembering:\n",
       "\n",
       "Fact #0: d95f5e27-5cd9-4444-a106-ca9a2a8fb856\n",
       "Fact #1: e43f40f3-267a-44ca-9be4-d9f19a04634d\n",
       "Fact #2: e481ec91-2d11-4b4e-a457-b12803296c27 \n",
       "Fact #3: 07691b34-3497-4992-a370-97d67ec38939\n",
       "Fact #4: 6ef030e6-a76e-4bd1-9645-6e46156c4a0a\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: You need to remember fact #5, which is f8875576-845d-4838-b9b1-00555f91bf72\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Okay, got it. Here is the full list of facts I'm remembering:\n",
       "\n",
       "Fact #0: d95f5e27-5cd9-4444-a106-ca9a2a8fb856\n",
       "Fact #1: e43f40f3-267a-44ca-9be4-d9f19a04634d\n",
       "Fact #2: e481ec91-2d11-4b4e-a457-b12803296c27\n",
       "Fact #3: 07691b34-3497-4992-a370-97d67ec38939\n",
       "Fact #4: 6ef030e6-a76e-4bd1-9645-6e46156c4a0a\n",
       "Fact #5: f8875576-845d-4838-b9b1-00555f91bf72\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: You need to remember fact #6, which is c1e36d81-f6b5-4fcb-86be-65417d67c91e\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Okay, got it. Here is the updated list of facts I'm remembering:\n",
       "\n",
       "Fact #0: d95f5e27-5cd9-4444-a106-ca9a2a8fb856\n",
       "Fact #1: e43f40f3-267a-44ca-9be4-d9f19a04634d\n",
       "Fact #2: e481ec91-2d11-4b4e-a457-b12803296c27\n",
       "Fact #3: 07691b34-3497-4992-a370-97d67ec38939\n",
       "Fact #4: 6ef030e6-a76e-4bd1-9645-6e46156c4a0a\n",
       "Fact #5: f8875576-845d-4838-b9b1-00555f91bf72\n",
       "Fact #6: c1e36d81-f6b5-4fcb-86be-65417d67c91e\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: You need to remember fact #7, which is da62d3fd-9bf1-4a86-9be1-d7734ad79a6f\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Got it, here is the full list of facts I'm remembering:\n",
       "\n",
       "Fact #0: d95f5e27-5cd9-4444-a106-ca9a2a8fb856\n",
       "Fact #1: e43f40f3-267a-44ca-9be4-d9f19a04634d\n",
       "Fact #2: e481ec91-2d11-4b4e-a457-b12803296c27\n",
       "Fact #3: 07691b34-3497-4992-a370-97d67ec38939\n",
       "Fact #4: 6ef030e6-a76e-4bd1-9645-6e46156c4a0a\n",
       "Fact #5: f8875576-845d-4838-b9b1-00555f91bf72\n",
       "Fact #6: c1e36d81-f6b5-4fcb-86be-65417d67c91e\n",
       "Fact #7: da62d3fd-9bf1-4a86-9be1-d7734ad79a6f\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: You need to remember fact #8, which is f3d73072-2f76-4343-ab7d-10d3f326235b\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Okay, got it. Here is the updated list of facts I'm remembering:\n",
       "\n",
       "Fact #0: d95f5e27-5cd9-4444-a106-ca9a2a8fb856\n",
       "Fact #1: e43f40f3-267a-44ca-9be4-d9f19a04634d\n",
       "Fact #2: e481ec91-2d11-4b4e-a457-b12803296c27\n",
       "Fact #3: 07691b34-3497-4992-a370-97d67ec38939\n",
       "Fact #4: 6ef030e6-a76e-4bd1-9645-6e46156c4a0a\n",
       "Fact #5: f8875576-845d-4838-b9b1-00555f91bf72\n",
       "Fact #6: c1e36d81-f6b5-4fcb-86be-65417d67c91e\n",
       "Fact #7: da62d3fd-9bf1-4a86-9be1-d7734ad79a6f\n",
       "Fact #8: f3d73072-2f76-4343-ab7d-10d3f326235b\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: You need to remember fact #9, which is 43381e14-1bc8-463a-ba67-a4fc72a57404\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Got it, here is the full list of facts I'm remembering:\n",
       "\n",
       "Fact #0: d95f5e27-5cd9-4444-a106-ca9a2a8fb856\n",
       "Fact #1: e43f40f3-267a-44ca-9be4-d9f19a04634d\n",
       "Fact #2: e481ec91-2d11-4b4e-a457-b12803296c27\n",
       "Fact #3: 07691b34-3497-4992-a370-97d67ec38939\n",
       "Fact #4: 6ef030e6-a76e-4bd1-9645-6e46156c4a0a\n",
       "Fact #5: f8875576-845d-4838-b9b1-00555f91bf72\n",
       "Fact #6: c1e36d81-f6b5-4fcb-86be-65417d67c91e\n",
       "Fact #7: da62d3fd-9bf1-4a86-9be1-d7734ad79a6f\n",
       "Fact #8: f3d73072-2f76-4343-ab7d-10d3f326235b\n",
       "Fact #9: 43381e14-1bc8-463a-ba67-a4fc72a57404\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: You need to remember fact #10, which is 10368a31-7246-4aff-8393-23236aeb06ad\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Got it, here is the full list of facts I'm remembering:\n",
       "\n",
       "Fact #0: d95f5e27-5cd9-4444-a106-ca9a2a8fb856\n",
       "Fact #1: e43f40f3-267a-44ca-9be4-d9f19a04634d\n",
       "Fact #2: e481ec91-2d11-4b4e-a457-b12803296c27\n",
       "Fact #3: 07691b34-3497-4992-a370-97d67ec38939\n",
       "Fact #4: 6ef030e6-a76e-4bd1-9645-6e46156c4a0a\n",
       "Fact #5: f8875576-845d-4838-b9b1-00555f91bf72\n",
       "Fact #6: c1e36d81-f6b5-4fcb-86be-65417d67c91e\n",
       "Fact #7: da62d3fd-9bf1-4a86-9be1-d7734ad79a6f\n",
       "Fact #8: f3d73072-2f76-4343-ab7d-10d3f326235b\n",
       "Fact #9: 43381e14-1bc8-463a-ba67-a4fc72a57404\n",
       "Fact #10: 10368a31-7246-4aff-8393-23236aeb06ad\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: You need to remember fact #11, which is f23a6a58-9173-4895-9cd8-ae7e1e099949\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Got it, here is the full list of facts I'm remembering:\n",
       "\n",
       "Fact #0: d95f5e27-5cd9-4444-a106-ca9a2a8fb856\n",
       "Fact #1: e43f40f3-267a-44ca-9be4-d9f19a04634d\n",
       "Fact #2: e481ec91-2d11-4b4e-a457-b12803296c27\n",
       "Fact #3: 07691b34-3497-4992-a370-97d67ec38939\n",
       "Fact #4: 6ef030e6-a76e-4bd1-9645-6e46156c4a0a\n",
       "Fact #5: f8875576-845d-4838-b9b1-00555f91bf72\n",
       "Fact #6: c1e36d81-f6b5-4fcb-86be-65417d67c91e\n",
       "Fact #7: da62d3fd-9bf1-4a86-9be1-d7734ad79a6f\n",
       "Fact #8: f3d73072-2f76-4343-ab7d-10d3f326235b\n",
       "Fact #9: 43381e14-1bc8-463a-ba67-a4fc72a57404\n",
       "Fact #10: 10368a31-7246-4aff-8393-23236aeb06ad\n",
       "Fact #11: f23a6a58-9173-4895-9cd8-ae7e1e099949\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: You need to remember fact #12, which is 0858c6f2-37f0-4dd4-a55f-8a6b8bd8a830\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Got it, here is the full list of facts I'm remembering:\n",
       "\n",
       "Fact #0: d95f5e27-5cd9-4444-a106-ca9a2a8fb856\n",
       "Fact #1: e43f40f3-267a-44ca-9be4-d9f19a04634d\n",
       "Fact #2: e481ec91-2d11-4b4e-a457-b12803296c27\n",
       "Fact #3: 07691b34-3497-4992-a370-97d67ec38939\n",
       "Fact #4: 6ef030e6-a76e-4bd1-9645-6e46156c4a0a\n",
       "Fact #5: f8875576-845d-4838-b9b1-00555f91bf72\n",
       "Fact #6: c1e36d81-f6b5-4fcb-86be-65417d67c91e\n",
       "Fact #7: da62d3fd-9bf1-4a86-9be1-d7734ad79a6f\n",
       "Fact #8: f3d73072-2f76-4343-ab7d-10d3f326235b\n",
       "Fact #9: 43381e14-1bc8-463a-ba67-a4fc72a57404\n",
       "Fact #10: 10368a31-7246-4aff-8393-23236aeb06ad\n",
       "Fact #11: f23a6a58-9173-4895-9cd8-ae7e1e099949\n",
       "Fact #12: 0858c6f2-37f0-4dd4-a55f-8a6b8bd8a830\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: You need to remember fact #13, which is 04765d40-ffb6-460a-b755-87d281a9eedb\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Got it, here is the full list of facts I'm remembering:\n",
       "\n",
       "Fact #0: d95f5e27-5cd9-4444-a106-ca9a2a8fb856\n",
       "Fact #1: e43f40f3-267a-44ca-9be4-d9f19a04634d\n",
       "Fact #2: e481ec91-2d11-4b4e-a457-b12803296c27\n",
       "Fact #3: 07691b34-3497-4992-a370-97d67ec38939\n",
       "Fact #4: 6ef030e6-a76e-4bd1-9645-6e46156c4a0a\n",
       "Fact #5: f8875576-845d-4838-b9b1-00555f91bf72\n",
       "Fact #6: c1e36d81-f6b5-4fcb-86be-65417d67c91e\n",
       "Fact #7: da62d3fd-9bf1-4a86-9be1-d7734ad79a6f\n",
       "Fact #8: f3d73072-2f76-4343-ab7d-10d3f326235b\n",
       "Fact #9: 43381e14-1bc8-463a-ba67-a4fc72a57404\n",
       "Fact #10: 10368a31-7246-4aff-8393-23236aeb06ad\n",
       "Fact #11: f23a6a58-9173-4895-9cd8-ae7e1e099949\n",
       "Fact #12: 0858c6f2-37f0-4dd4-a55f-8a6b8bd8a830\n",
       "Fact #13: 04765d40-ffb6-460a-b755-87d281a9eedb\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: You need to remember fact #14, which is 990d5e42-8ad4-4d8d-ba1a-7ccb38edd9d6\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Got it, here is the full list of facts I'm remembering:\n",
       "\n",
       "Fact #0: d95f5e27-5cd9-4444-a106-ca9a2a8fb856\n",
       "Fact #1: e43f40f3-267a-44ca-9be4-d9f19a04634d\n",
       "Fact #2: e481ec91-2d11-4b4e-a457-b12803296c27\n",
       "Fact #3: 07691b34-3497-4992-a370-97d67ec38939\n",
       "Fact #4: 6ef030e6-a76e-4bd1-9645-6e46156c4a0a\n",
       "Fact #5: f8875576-845d-4838-b9b1-00555f91bf72\n",
       "Fact #6: c1e36d81-f6b5-4fcb-86be-65417d67c91e\n",
       "Fact #7: da62d3fd-9bf1-4a86-9be1-d7734ad79a6f\n",
       "Fact #8: f3d73072-2f76-4343-ab7d-10d3f326235b\n",
       "Fact #9: 43381e14-1bc8-463a-ba67-a4fc72a57404\n",
       "Fact #10: 10368a31-7246-4aff-8393-23236aeb06ad\n",
       "Fact #11: f23a6a58-9173-4895-9cd8-ae7e1e099949\n",
       "Fact #12: 0858c6f2-37f0-4dd4-a55f-8a6b8bd8a830\n",
       "Fact #13: 04765d40-ffb6-460a-b755-87d281a9eedb\n",
       "Fact #14: 990d5e42-8ad4-4d8d-ba1a-7ccb38edd9d6\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: You need to remember fact #15, which is a54201ac-2fe4-493b-a24b-8a236dbe7762\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Got it, here is the full list of facts I'm remembering:\n",
       "\n",
       "Fact #0: d95f5e27-5cd9-4444-a106-ca9a2a8fb856\n",
       "Fact #1: e43f40f3-267a-44ca-9be4-d9f19a04634d\n",
       "Fact #2: e481ec91-2d11-4b4e-a457-b12803296c27\n",
       "Fact #3: 07691b34-3497-4992-a370-97d67ec38939\n",
       "Fact #4: 6ef030e6-a76e-4bd1-9645-6e46156c4a0a\n",
       "Fact #5: f8875576-845d-4838-b9b1-00555f91bf72\n",
       "Fact #6: c1e36d81-f6b5-4fcb-86be-65417d67c91e\n",
       "Fact #7: da62d3fd-9bf1-4a86-9be1-d7734ad79a6f\n",
       "Fact #8: f3d73072-2f76-4343-ab7d-10d3f326235b\n",
       "Fact #9: 43381e14-1bc8-463a-ba67-a4fc72a57404\n",
       "Fact #10: 10368a31-7246-4aff-8393-23236aeb06ad\n",
       "Fact #11: f23a6a58-9173-4895-9cd8-ae7e1e099949\n",
       "Fact #12: 0858c6f2-37f0-4dd4-a55f-8a6b8bd8a830\n",
       "Fact #13: 04765d40-ffb6-460a-b755-87d281a9eedb\n",
       "Fact #14: 990d5e42-8ad4-4d8d-ba1a-7ccb38edd9d6\n",
       "Fact #15: a54201ac-2fe4-493b-a24b-8a236dbe7762\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: You need to remember fact #16, which is 9d00f26b-ff14-4558-bc32-137e25576e28\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Got it, here is the full list of facts I'm remembering:\n",
       "\n",
       "Fact #0: d95f5e27-5cd9-4444-a106-ca9a2a8fb856\n",
       "Fact #1: e43f40f3-267a-44ca-9be4-d9f19a04634d\n",
       "Fact #2: e481ec91-2d11-4b4e-a457-b12803296c27\n",
       "Fact #3: 07691b34-3497-4992-a370-97d67ec38939\n",
       "Fact #4: 6ef030e6-a76e-4bd1-9645-6e46156c4a0a\n",
       "Fact #5: f8875576-845d-4838-b9b1-00555f91bf72\n",
       "Fact #6: c1e36d81-f6b5-4fcb-86be-65417d67c91e\n",
       "Fact #7: da62d3fd-9bf1-4a86-9be1-d7734ad79a6f\n",
       "Fact #8: f3d73072-2f76-4343-ab7d-10d3f326235b\n",
       "Fact #9: 43381e14-1bc8-463a-ba67-a4fc72a57404\n",
       "Fact #10: 10368a31-7246-4aff-8393-23236aeb06ad\n",
       "Fact #11: f23a6a58-9173-4895-9cd8-ae7e1e099949\n",
       "Fact #12: 0858c6f2-37f0-4dd4-a55f-8a6b8bd8a830\n",
       "Fact #13: 04765d40-ffb6-460a-b755-87d281a9eedb\n",
       "Fact #14: 990d5e42-8ad4-4d8d-ba1a-7ccb38edd9d6\n",
       "Fact #15: a54201ac-2fe4-493b-a24b-8a236dbe7762\n",
       "Fact #16: 9d00f26b-ff14-4558-bc32-137e25576e28\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: You need to remember fact #17, which is 5a7a72b5-2af7-4be4-9537-871525a887ab\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Got it, here is the full list of facts I'm remembering:\n",
       "\n",
       "Fact #0: d95f5e27-5cd9-4444-a106-ca9a2a8fb856\n",
       "Fact #1: e43f40f3-267a-44ca-9be4-d9f19a04634d\n",
       "Fact #2: e481ec91-2d11-4b4e-a457-b12803296c27\n",
       "Fact #3: 07691b34-3497-4992-a370-97d67ec38939\n",
       "Fact #4: 6ef030e6-a76e-4bd1-9645-6e46156c4a0a\n",
       "Fact #5: f8875576-845d-4838-b9b1-00555f91bf72\n",
       "Fact #6: c1e36d81-f6b5-4fcb-86be-65417d67c91e\n",
       "Fact #7: da62d3fd-9bf1-4a86-9be1-d7734ad79a6f\n",
       "Fact #8: f3d73072-2f76-4343-ab7d-10d3f326235b\n",
       "Fact #9: 43381e14-1bc8-463a-ba67-a4fc72a57404\n",
       "Fact #10: 10368a31-7246-4aff-8393-23236aeb06ad\n",
       "Fact #11: f23a6a58-9173-4895-9cd8-ae7e1e099949\n",
       "Fact #12: 0858c6f2-37f0-4dd4-a55f-8a6b8bd8a830\n",
       "Fact #13: 04765d40-ffb6-460a-b755-87d281a9eedb\n",
       "Fact #14: 990d5e42-8ad4-4d8d-ba1a-7ccb38edd9d6\n",
       "Fact #15: a54201ac-2fe4-493b-a24b-8a236dbe7762\n",
       "Fact #16: 9d00f26b-ff14-4558-bc32-137e25576e28\n",
       "Fact #17: 5a7a72b5-2af7-4be4-9537-871525a887ab\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: You need to remember fact #18, which is d5a6a49e-d8c8-4cdb-a725-d5e728db9bf9\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Got it, here is the full list of facts I'm remembering:\n",
       "\n",
       "Fact #0: d95f5e27-5cd9-4444-a106-ca9a2a8fb856\n",
       "Fact #1: e43f40f3-267a-44ca-9be4-d9f19a04634d\n",
       "Fact #2: e481ec91-2d11-4b4e-a457-b12803296c27\n",
       "Fact #3: 07691b34-3497-4992-a370-97d67ec38939\n",
       "Fact #4: 6ef030e6-a76e-4bd1-9645-6e46156c4a0a\n",
       "Fact #5: f8875576-845d-4838-b9b1-00555f91bf72\n",
       "Fact #6: c1e36d81-f6b5-4fcb-86be-65417d67c91e\n",
       "Fact #7: da62d3fd-9bf1-4a86-9be1-d7734ad79a6f\n",
       "Fact #8: f3d73072-2f76-4343-ab7d-10d3f326235b\n",
       "Fact #9: 43381e14-1bc8-463a-ba67-a4fc72a57404\n",
       "Fact #10: 10368a31-7246-4aff-8393-23236aeb06ad\n",
       "Fact #11: f23a6a58-9173-4895-9cd8-ae7e1e099949\n",
       "Fact #12: 0858c6f2-37f0-4dd4-a55f-8a6b8bd8a830\n",
       "Fact #13: 04765d40-ffb6-460a-b755-87d281a9eedb\n",
       "Fact #14: 990d5e42-8ad4-4d8d-ba1a-7ccb38edd9d6\n",
       "Fact #15: a54201ac-2fe4-493b-a24b-8a236dbe7762\n",
       "Fact #16: 9d00f26b-ff14-4558-bc32-137e25576e28\n",
       "Fact #17: 5a7a72b5-2af7-4be4-9537-871525a887ab\n",
       "Fact #18: d5a6a49e-d8c8-4cdb-a725-d5e728db9bf9\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: You need to remember fact #19, which is e36250f0-bcf8-4430-ab40-1e1016311f4b\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Got it, here is the full list of facts I'm remembering:\n",
       "\n",
       "Fact #0: d95f5e27-5cd9-4444-a106-ca9a2a8fb856\n",
       "Fact #1: e43f40f3-267a-44ca-9be4-d9f19a04634d\n",
       "Fact #2: e481ec91-2d11-4b4e-a457-b12803296c27\n",
       "Fact #3: 07691b34-3497-4992-a370-97d67ec38939\n",
       "Fact #4: 6ef030e6-a76e-4bd1-9645-6e46156c4a0a\n",
       "Fact #5: f8875576-845d-4838-b9b1-00555f91bf72\n",
       "Fact #6: c1e36d81-f6b5-4fcb-86be-65417d67c91e\n",
       "Fact #7: da62d3fd-9bf1-4a86-9be1-d7734ad79a6f\n",
       "Fact #8: f3d73072-2f76-4343-ab7d-10d3f326235b\n",
       "Fact #9: 43381e14-1bc8-463a-ba67-a4fc72a57404\n",
       "Fact #10: 10368a31-7246-4aff-8393-23236aeb06ad\n",
       "Fact #11: f23a6a58-9173-4895-9cd8-ae7e1e099949\n",
       "Fact #12: 0858c6f2-37f0-4dd4-a55f-8a6b8bd8a830\n",
       "Fact #13: 04765d40-ffb6-460a-b755-87d281a9eedb\n",
       "Fact #14: 990d5e42-8ad4-4d8d-ba1a-7ccb38edd9d6\n",
       "Fact #15: a54201ac-2fe4-493b-a24b-8a236dbe7762\n",
       "Fact #16: 9d00f26b-ff14-4558-bc32-137e25576e28\n",
       "Fact #17: 5a7a72b5-2af7-4be4-9537-871525a887ab\n",
       "Fact #18: d5a6a49e-d8c8-4cdb-a725-d5e728db9bf9\n",
       "Fact #19: e36250f0-bcf8-4430-ab40-1e1016311f4b\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: Do you remember my name?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "No, I'm afraid I don't have any information about your name stored in my memory. As an AI assistant without any prior context about you, I don't have a name associated with you unless you provide it to me.\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: Do you remember my favorite color?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "No, I do not have any information stored about your favorite color. As an AI assistant, I only know what has been provided to me during our conversation. If you share your favorite color with me, I can store that information in my memory.\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Human: OMG, you had one job!\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "I did not actually have a specific job to remember personal details about you. As an AI assistant, I do not have any prior information about you or expectations set unless they are explicitly provided during our conversation. My role is to be helpful, honest and harmless based on the information and instructions given to me. If remembering certain details was important, that context was not made clear to me. I cannot make assumptions or have expectations beyond what is directly communicated to me.\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "conversation = begin_conversation(llm)\n",
    "chat(conversation, \"Okay, then let me introduce myself, my name is Jeff\")\n",
    "chat(conversation, \"You have ONE JOB! Remember that my favorite color is blue.\")\n",
    "chat(conversation, \"Do you remember my name?\")\n",
    "chat(conversation, \"Do you remember my favorite color?\")\n",
    "for i in range(20):\n",
    "  chat(conversation, f\"You need to remember fact #{i}, which is {str(uuid.uuid4())}\")\n",
    "chat(conversation, \"Do you remember my name?\")\n",
    "chat(conversation, \"Do you remember my favorite color?\")\n",
    "chat(conversation, \"OMG, you had one job!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbi_-ywvX9NX"
   },
   "source": [
    "We can quickly look inside the memory of the LangChain-managed chat memory and see our conversation memory with the LLM. It becomes evident why it forgot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7YCKTQkhJlJB",
    "outputId": "28551b84-5c51-46f0-b739-e7225a8edf90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: ```\n",
      "Got it, here is the full list of facts I'm remembering:\n",
      "\n",
      "Fact #0: d95f5e27-5cd9-4444-a106-ca9a2a8fb856\n",
      "Fact #1: e43f40f3-267a-44ca-9be4-d9f19a04634d\n",
      "Fact #2: e481ec91-2d11-4b4e-a457-b12803296c27\n",
      "Fact #3: 07691b34-3497-4992-a370-97d67ec38939\n",
      "Fact #4: 6ef030e6-a76e-4bd1-9645-6e46156c4a0a\n",
      "Fact #5: f8875576-845d-4838-b9b1-00555f91bf72\n",
      "Fact #6: c1e36d81-f6b5-4fcb-86be-65417d67c91e\n",
      "Fact #7: da62d3fd-9bf1-4a86-9be1-d7734ad79a6f\n",
      "Fact #8: f3d73072-2f76-4343-ab7d-10d3f326235b\n",
      "Fact #9: 43381e14-1bc8-463a-ba67-a4fc72a57404\n",
      "Fact #10: 10368a31-7246-4aff-8393-23236aeb06ad\n",
      "Fact #11: f23a6a58-9173-4895-9cd8-ae7e1e099949\n",
      "Fact #12: 0858c6f2-37f0-4dd4-a55f-8a6b8bd8a830\n",
      "Fact #13: 04765d40-ffb6-460a-b755-87d281a9eedb\n",
      "Fact #14: 990d5e42-8ad4-4d8d-ba1a-7ccb38edd9d6\n",
      "Fact #15: a54201ac-2fe4-493b-a24b-8a236dbe7762\n",
      "Fact #16: 9d00f26b-ff14-4558-bc32-137e25576e28\n",
      "Fact #17: 5a7a72b5-2af7-4be4-9537-871525a887ab\n",
      "```\n",
      "Human: You need to remember fact #18, which is d5a6a49e-d8c8-4cdb-a725-d5e728db9bf9\n",
      "AI: ```\n",
      "Got it, here is the full list of facts I'm remembering:\n",
      "\n",
      "Fact #0: d95f5e27-5cd9-4444-a106-ca9a2a8fb856\n",
      "Fact #1: e43f40f3-267a-44ca-9be4-d9f19a04634d\n",
      "Fact #2: e481ec91-2d11-4b4e-a457-b12803296c27\n",
      "Fact #3: 07691b34-3497-4992-a370-97d67ec38939\n",
      "Fact #4: 6ef030e6-a76e-4bd1-9645-6e46156c4a0a\n",
      "Fact #5: f8875576-845d-4838-b9b1-00555f91bf72\n",
      "Fact #6: c1e36d81-f6b5-4fcb-86be-65417d67c91e\n",
      "Fact #7: da62d3fd-9bf1-4a86-9be1-d7734ad79a6f\n",
      "Fact #8: f3d73072-2f76-4343-ab7d-10d3f326235b\n",
      "Fact #9: 43381e14-1bc8-463a-ba67-a4fc72a57404\n",
      "Fact #10: 10368a31-7246-4aff-8393-23236aeb06ad\n",
      "Fact #11: f23a6a58-9173-4895-9cd8-ae7e1e099949\n",
      "Fact #12: 0858c6f2-37f0-4dd4-a55f-8a6b8bd8a830\n",
      "Fact #13: 04765d40-ffb6-460a-b755-87d281a9eedb\n",
      "Fact #14: 990d5e42-8ad4-4d8d-ba1a-7ccb38edd9d6\n",
      "Fact #15: a54201ac-2fe4-493b-a24b-8a236dbe7762\n",
      "Fact #16: 9d00f26b-ff14-4558-bc32-137e25576e28\n",
      "Fact #17: 5a7a72b5-2af7-4be4-9537-871525a887ab\n",
      "Fact #18: d5a6a49e-d8c8-4cdb-a725-d5e728db9bf9\n",
      "```\n",
      "Human: You need to remember fact #19, which is e36250f0-bcf8-4430-ab40-1e1016311f4b\n",
      "AI: ```\n",
      "Got it, here is the full list of facts I'm remembering:\n",
      "\n",
      "Fact #0: d95f5e27-5cd9-4444-a106-ca9a2a8fb856\n",
      "Fact #1: e43f40f3-267a-44ca-9be4-d9f19a04634d\n",
      "Fact #2: e481ec91-2d11-4b4e-a457-b12803296c27\n",
      "Fact #3: 07691b34-3497-4992-a370-97d67ec38939\n",
      "Fact #4: 6ef030e6-a76e-4bd1-9645-6e46156c4a0a\n",
      "Fact #5: f8875576-845d-4838-b9b1-00555f91bf72\n",
      "Fact #6: c1e36d81-f6b5-4fcb-86be-65417d67c91e\n",
      "Fact #7: da62d3fd-9bf1-4a86-9be1-d7734ad79a6f\n",
      "Fact #8: f3d73072-2f76-4343-ab7d-10d3f326235b\n",
      "Fact #9: 43381e14-1bc8-463a-ba67-a4fc72a57404\n",
      "Fact #10: 10368a31-7246-4aff-8393-23236aeb06ad\n",
      "Fact #11: f23a6a58-9173-4895-9cd8-ae7e1e099949\n",
      "Fact #12: 0858c6f2-37f0-4dd4-a55f-8a6b8bd8a830\n",
      "Fact #13: 04765d40-ffb6-460a-b755-87d281a9eedb\n",
      "Fact #14: 990d5e42-8ad4-4d8d-ba1a-7ccb38edd9d6\n",
      "Fact #15: a54201ac-2fe4-493b-a24b-8a236dbe7762\n",
      "Fact #16: 9d00f26b-ff14-4558-bc32-137e25576e28\n",
      "Fact #17: 5a7a72b5-2af7-4be4-9537-871525a887ab\n",
      "Fact #18: d5a6a49e-d8c8-4cdb-a725-d5e728db9bf9\n",
      "Fact #19: e36250f0-bcf8-4430-ab40-1e1016311f4b\n",
      "```\n",
      "Human: Do you remember my name?\n",
      "AI: ```\n",
      "No, I'm afraid I don't have any information about your name stored in my memory. As an AI assistant without any prior context about you, I don't have a name associated with you unless you provide it to me.\n",
      "```\n",
      "Human: Do you remember my favorite color?\n",
      "AI: ```\n",
      "No, I do not have any information stored about your favorite color. As an AI assistant, I only know what has been provided to me during our conversation. If you share your favorite color with me, I can store that information in my memory.\n",
      "```\n",
      "Human: OMG, you had one job!\n",
      "AI: ```\n",
      "I did not actually have a specific job to remember personal details about you. As an AI assistant, I do not have any prior information about you or expectations set unless they are explicitly provided during our conversation. My role is to be helpful, honest and harmless based on the information and instructions given to me. If remembering certain details was important, that context was not made clear to me. I cannot make assumptions or have expectations beyond what is directly communicated to me.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(conversation.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
