{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whjsJasuhstV"
   },
   "source": [
    "# Introduction to Automation with LangChain, Generative AI, and Python\n",
    "**2.4: LLM Writes a Book**\n",
    "* Instructor: [Jeff Heaton](https://youtube.com/@HeatonResearch), WUSTL Center for Analytics and Business Insight (CABI), [Washington University in St. Louis](https://olin.wustl.edu/faculty-and-research/research-centers/center-for-analytics-and-business-insight/index.php)\n",
    "* For more information visit the [class website](https://github.com/jeffheaton/cabi_genai_automation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pC9A-LaYhsta"
   },
   "source": [
    "This section will demonstrate how to effectively utilize the LLM to write a book. Writing a book is a uniquely complex challenge that requires planning and execution. Unlike simpler tasks, drafting a full-length book is a journey that extends beyond a single session with an LLM due to its extensive length and depth. However, with a systematic approach, you can harness the capabilities of an LLM to create a comprehensive manuscript, empowering you to conquer this challenge.\n",
    "\n",
    "This section presents a method to craft a book using an LLM, which involves breaking down the book creation process into manageable segments. Our journey begins with a foundational step: selecting a subject for the book. Once a subject is chosen, the process unfolds through a series of iterative interactions with the LLM, each building upon the last to gradually construct the complete book, igniting your passion for writing.\n",
    "\n",
    "Initially, we prompt the LLM to generate a random title based on the given subject. This title sets the thematic tone for the book and guides the subsequent steps. Following the title, we request the LLM to create a random synopsis. This synopsis acts as a narrative backbone, offering a brief overview of the bookâ€™s content and direction.\n",
    "\n",
    "With a synopsis, the next step is to generate a table of contents. This table outlines the main chapters and sections of the book, providing a structured framework that organizes the content logically and cohesively. It is from this framework that the book starts to take shape.\n",
    "The next phase involves creating each chapter. We engage in a focused session with the LLM for every chapter outlined in the table of contents. During each session, we provide the LLM with the synopsis and the complete table of contents to ensure consistency and continuity throughout the book. This iterative process allows each chapter to be crafted with attention to detail, ensuring it aligns with the previously established narrative and thematic elements.\n",
    "\n",
    "By methodically iterating through these steps, we harness the capabilities of an LLM to transform a simple idea into a detailed and well-structured book. This chapter will guide you through each stage, providing practical advice on collaborating with an LLM to achieve more complex tasks.\n",
    "\n",
    "We begin by accessing a large language model with a temperature of 0.7. We use a higher temperature to encourage creativity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dfISNTpwOKiZ"
   },
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain import OpenAI, PromptTemplate\n",
    "from langchain_aws import ChatBedrock\n",
    "from IPython.display import display_markdown\n",
    "\n",
    "MODEL = 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "\n",
    "# Initialize bedrock, use built in role\n",
    "llm = ChatBedrock(\n",
    "    model_id=MODEL,\n",
    "    model_kwargs={\"temperature\": 0.7},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLUWbW7NRp4m"
   },
   "source": [
    "We create a simple utility function to query the LLM with a custom system prompt. The system prompt tells the LLM that it is assisting in creating a book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "v8vGrZcjTvwZ"
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "def query_llm(prompt):\n",
    "  messages = [\n",
    "      SystemMessage(\n",
    "          content=\"\"\"\n",
    "You are writing a book, return just what I ask you for. Do not add comments, \n",
    "it is very important that you only provide the final output without any \n",
    "additional comments or remarks. Do not repeat my command or a summary of my\n",
    "command.\n",
    "\"\"\"\n",
    "      ),\n",
    "      HumanMessage(\n",
    "          content=prompt\n",
    "      ),\n",
    "  ]\n",
    "\n",
    "  output = llm.invoke(messages)\n",
    "  return output.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FOWb0XT7RlYg"
   },
   "source": [
    "## Generate Title, Synopsis and Table of Contents\n",
    "\n",
    "For this book, we allow the user to specify the subject specified by the SUBJECT variable. We then request the LLM to generate a random title based on this subject. It is essential that the prompt request that the LLM only the; LLMs often like to prefix with text such as \"Here is a random title.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YpEgTYV1TvpH",
    "outputId": "d34dd6e9-03e4-4ea7-b021-f567d9554548"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rogue Operative: Betrayal at the Khyber Pass\n"
     ]
    }
   ],
   "source": [
    "SUBJECT = \"international spy story\"\n",
    "\n",
    "title = query_llm(f\"\"\"\n",
    "Give me a random title for a book on the subject '{SUBJECT}'.\n",
    "Return only the title, no additional text.\n",
    "\"\"\").strip(\" '\\\"\")\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXyOF_oYtMlR"
   },
   "source": [
    "Now that we have a title, we can request a random synopsis of the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KxYdLzYCTvgQ",
    "outputId": "8d46d6b7-26cc-41f9-e52b-2e63432e0af8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a world of shifting alliances and hidden agendas, a daring secret agent must navigate a treacherous web of deceit and intrigue that spans continents. Caught in the crosshairs of rival intelligence agencies and powerful criminal organizations, they race against time to unravel a conspiracy that threatens global stability. With each heart-pounding twist and turn, this international spy story takes readers on a thrilling journey through exotic locales and high-stakes espionage, where trust is a luxury and one wrong move could be fatal.\n"
     ]
    }
   ],
   "source": [
    "synopsis = query_llm(f\"\"\"\n",
    "Give me just a synopsis for a book of the title '{SUBJECT}' for a book on the subject '{SUBJECT}'.\n",
    "\"\"\").strip(\" '\\\"\")\n",
    "print(synopsis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6ju-lJEttjw"
   },
   "source": [
    "Next, we generate the table of contents. For this generation, we provide all previous information. We also request a particular format for the table of contents. You may notice that I ask for the chapter numbers, even though they are an increasing numeric count and could easily be derived. This process works better because the LLM wants to provide the chapter numbers, and attempts to suppress chapter numbers are often inconsistent. It is easier to allow the LLM to generate chapter numbers but control where it generates them so that I can consistently remove them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9IhXP9PJTvXq",
    "outputId": "05c1b524-7aa0-41fa-c8d3-cc79220f6004"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1|Whispers in the Night\n",
      "2|The Khyber Gambit\n",
      "3|Betrayal in Marrakech\n",
      "4|Shadows in Moscow\n",
      "5|The Hong Kong Connection\n",
      "6|Echoes of Deception\n",
      "7|Endgame in Istanbul\n",
      "8|Secrets Unveiled\n",
      "9|The Reckoning\n",
      "10|A New Dawn\n"
     ]
    }
   ],
   "source": [
    "toc = query_llm(f\"\"\"\n",
    "Give me a table of contents for a book of the title '{title}' for a book on\n",
    "the subject '{SUBJECT}' the book synopsis is '{synopsis}'.\n",
    "Return the table of contents as a list of chapter titles.\n",
    "Separate the chapter number and chapter title with a pipe character '|'.\n",
    "Do not give me any line that is not a chapter!\n",
    "\"\"\").strip(\" '\\\"\")\n",
    "print(toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mvh6hlVBCN2f"
   },
   "source": [
    "We must now parse the table of contents and remove the pipes and chapter numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-A4RgyR3Mid",
    "outputId": "85f1d678-61ea-47b9-cac0-a1596a55a905"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1|Whispers in the Night', '2|The Khyber Gambit', '3|Betrayal in Marrakech', '4|Shadows in Moscow', '5|The Hong Kong Connection', '6|Echoes of Deception', '7|Endgame in Istanbul', '8|Secrets Unveiled', '9|The Reckoning', '10|A New Dawn']\n",
      "['Whispers in the Night', 'The Khyber Gambit', 'Betrayal in Marrakech', 'Shadows in Moscow', 'The Hong Kong Connection', 'Echoes of Deception', 'Endgame in Istanbul', 'Secrets Unveiled', 'The Reckoning', 'A New Dawn']\n"
     ]
    }
   ],
   "source": [
    "# Split the string into lines\n",
    "lines = toc.splitlines()\n",
    "print(lines)\n",
    "\n",
    "# Extract titles using list comprehension\n",
    "toc2 = [line.split('|')[1].strip() for line in lines if line]\n",
    "\n",
    "# Print the list of titles\n",
    "print(toc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vMXLYGi_RxNp"
   },
   "source": [
    "## Generate the Chapters of the Book\n",
    "\n",
    "Next, we create a function capable of producing the text that makes up a chapter. To ensure that the function has enough context to generate each chapter, we provide the synopsis, the table of contents, and the chapter number. To test this code, we request that it develop a single chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ATXhVI9NfUTQ",
    "outputId": "e4d84d2b-18e2-4997-cc4a-052ef0666716"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The night was still and silent, save for the faint whispers carried by the desert wind. In a remote outpost nestled in the rugged mountains of the Khyber Pass, a lone figure moved with practiced stealth, their footsteps leaving no trace on the sun-baked earth.\n",
      "\n",
      "Agent Zara Khalil, one of the most skilled operatives in the covert world, had been tasked with a mission of utmost importance. Intelligence reports had hinted at a nefarious plot brewing in the shadows, one that threatened to destabilize the delicate balance of power in the region.\n",
      "\n",
      "As she made her way through the narrow alleys and winding streets, Zara's senses were heightened, alert to the slightest movement or sound that could betray an enemy presence. Her years of training had honed her instincts to a razor's edge, allowing her to navigate the treacherous terrain with the grace of a seasoned predator.\n",
      "\n",
      "Reaching her destination, a nondescript building that served as a front for a local arms dealer, Zara slipped through the shadows, her movements fluid and silent. Inside, the dim lighting cast eerie shadows across the walls, and the air was thick with the scent of gunpowder and greed.\n",
      "\n",
      "With a deft hand, she disarmed the rudimentary security system and made her way deeper into the compound, her gaze scanning for any sign of her target. The intelligence had been sketchy, but she knew that this was the key to unraveling the larger conspiracy that threatened to engulf the region.\n",
      "\n",
      "As she rounded a corner, Zara froze, her breath caught in her throat. Before her stood a man she recognized from the dossier â€“ Khalid Ansari, a notorious arms dealer with ties to various terrorist organizations. He was engaged in a heated conversation with another figure, their voices hushed but laced with urgency.\n",
      "\n",
      "Zara strained to catch the words, her heart pounding in her chest. Fragments of their discussion filtered through the haze of tension, mentions of a shipment, a rendezvous point, and a code name that sent a chill down her spine: \"Operation Scorpion's Sting.\"\n",
      "\n",
      "Suddenly, a floorboard creaked beneath her foot, and in an instant, the room erupted into chaos. Gunfire erupted, and Zara found herself embroiled in a deadly dance, her body moving with practiced precision as she returned fire, her mind racing to piece together the puzzle that was rapidly unfolding before her.\n",
      "\n",
      "Amidst the chaos, she caught a glimpse of Ansari fleeing through a hidden exit, his face twisted in a mixture of fear and determination. Without hesitation, Zara gave chase, her feet pounding against the dusty ground as she pursued her quarry through the winding backstreets and alleyways of the outpost.\n",
      "\n",
      "The chase led them deep into the heart of the Khyber Pass, where the rugged terrain became their battleground. Bullets whizzed past her, kicking up plumes of dust and rock, as Zara weaved and dodged, her focus unwavering.\n",
      "\n",
      "Finally, in a secluded ravine, she cornered Ansari, his back against the unyielding rock face. His eyes were wild, his breath ragged, and in that moment, Zara knew she held the key to unraveling the larger conspiracy.\n",
      "\n",
      "With a steely determination, she pressed him for answers, her questions cutting through the tense silence like a razor-sharp blade. Ansari, realizing the futility of his situation, began to spill the secrets he had been harboring, each revelation more chilling than the last.\n",
      "\n",
      "As the night gave way to dawn, Zara emerged from the ravine, her mind reeling with the information she had uncovered. Operation Scorpion's Sting was far more sinister than she could have imagined, a plot that threatened to plunge the region into chaos and bloodshed.\n",
      "\n",
      "With a renewed sense of urgency, she knew that time was of the essence. The trail had gone cold, but she had a lead â€“ a whisper of a name, a hint of a location that could unravel the entire conspiracy. Her next stop: Marrakech, where the threads of betrayal would begin to unwind, and the true nature of the threat would be revealed.\n"
     ]
    }
   ],
   "source": [
    "def render_chapter(num, chapter_title, title, subject, synopsis, toc):\n",
    "  txt = query_llm(f\"\"\"\n",
    "  Write Chapter {num}, titled \"{chapter_title}\" for a book of the title '{title}' for a book on\n",
    "  the subject '{subject}' the book synopsis is '{synopsis}' the table of contents is '{toc}'.\n",
    "  Give me only the chapter text, no chapter heading, no chapter title, number, no additional text.\n",
    "  Make sure the chapter is at least 3,000 to 4,000 words. End with a complete sentence, do not cut off.\n",
    "  \"\"\").strip(\" '\\\"\")\n",
    "  return txt\n",
    "\n",
    "txt = render_chapter(1, toc2[0], title, SUBJECT, synopsis, toc)\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6s7Igm5cSf50"
   },
   "source": [
    "We can now generate the entire book in Markdown, which allows some formatting. We begin by rendering the title and synopsis, the table of contents, and each chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uq8xv3RIBkIv",
    "outputId": "4663ad20-d60c-4c89-ee0a-40a6b87203b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendering chapter 1/10: Whispers in the Night\n",
      "Rendering chapter 2/10: The Khyber Gambit\n",
      "Rendering chapter 3/10: Betrayal in Marrakech\n",
      "Rendering chapter 4/10: Shadows in Moscow\n",
      "Rendering chapter 5/10: The Hong Kong Connection\n",
      "Rendering chapter 6/10: Echoes of Deception\n",
      "Rendering chapter 7/10: Endgame in Istanbul\n",
      "Rendering chapter 8/10: Secrets Unveiled\n",
      "Rendering chapter 9/10: The Reckoning\n",
      "Rendering chapter 10/10: A New Dawn\n"
     ]
    }
   ],
   "source": [
    "book = \"\"\n",
    "\n",
    "# Render the title and synopsis\n",
    "book += f\"# {title}\\n\"\n",
    "book += f\"{synopsis}\\n\"\n",
    "\n",
    "# Render the toc\n",
    "book += f\"\\n## Table of Contents\\n\\n\"\n",
    "num = 1\n",
    "for chapter_title in toc2:\n",
    "  book += f\"{num}. {chapter_title}\\n\"\n",
    "  num += 1\n",
    "\n",
    "# Render the book\n",
    "chapter = 1\n",
    "for chapter_title in toc2:\n",
    "  print(f\"Rendering chapter {chapter}/{len(toc2)}: {chapter_title}\")\n",
    "  txt = render_chapter(chapter, chapter_title, title, SUBJECT, synopsis, toc)\n",
    "  book += f\"\\n\\n## Chapter {chapter}: {chapter_title}\\n\"\n",
    "  book += f\"{txt}\\n\"\n",
    "  chapter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXVa0IxKR5V7"
   },
   "source": [
    "## Generate a PDF of the Book\n",
    "\n",
    "Now that we have generated the book, we have saved it as a PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DJNvL2xsfVoF",
    "outputId": "c25db4be-558b-49a6-9523-ecfb07d30aea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import markdown\n",
    "import pdfkit\n",
    "\n",
    "# Convert Markdown to HTML\n",
    "html = markdown.markdown(book)\n",
    "\n",
    "# Convert HTML to PDF\n",
    "pdfkit.from_string(html, 'output.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
