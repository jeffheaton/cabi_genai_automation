{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whjsJasuhstV"
   },
   "source": [
    "# Introduction to Automation with LangChain, Generative AI, and Python\n",
    "**4.1: Image Generation**\n",
    "* Instructor: [Jeff Heaton](https://youtube.com/@HeatonResearch), WUSTL Center for Analytics and Business Insight (CABI), [Washington University in St. Louis](https://olin.wustl.edu/faculty-and-research/research-centers/center-for-analytics-and-business-insight/index.php)\n",
    "* For more information visit the [class website](https://github.com/jeffheaton/cabi_genai_automation).\n",
    "\n",
    "## Automatic TA\n",
    "\n",
    "We will now see how we can use a LLM to act as a teaching assistant, and answer emails for an instructor. We begin by defining a model and a simple function to load data from URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dfISNTpwOKiZ"
   },
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain import OpenAI, PromptTemplate\n",
    "from langchain_aws import ChatBedrock\n",
    "from IPython.display import display_markdown\n",
    "import requests\n",
    "\n",
    "MODEL = 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "\n",
    "# Initialize bedrock, use built in role\n",
    "llm = ChatBedrock(\n",
    "    model_id=MODEL,\n",
    "    model_kwargs={\"temperature\": 0.0},\n",
    ")\n",
    "\n",
    "def fetch_url_content(url):\n",
    "    try:\n",
    "        # Send a GET request to the URL\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Return the content as a string\n",
    "        return response.text\n",
    "    \n",
    "    except requests.RequestException as e:\n",
    "        # Return the error message if the request failed\n",
    "        return f\"An error occurred: {e}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a simple chain that provides instructions and expects four pieces of information to process.\n",
    "\n",
    "* [email](https://data.heatonresearch.com/wustl/CABI/genai-langchain/autohelp/autohelp_email_1.txt) - The email that the student wrote, asking for help.\n",
    "* [code](https://data.heatonresearch.com/wustl/CABI/genai-langchain/autohelp/autohelp_code_1.txt) - Any code that the student provided for the question.\n",
    "* [instructions](https://data.heatonresearch.com/wustl/CABI/genai-langchain/autohelp/autohelp_instructions_1.txt) - The instructions the professor gave.\n",
    "* [solution](https://data.heatonresearch.com/wustl/CABI/genai-langchain/autohelp/autohelp_solution_1.txt) - The solution to this assignment, created by the professor.\n",
    "\n",
    "The following code sets up this prompt and chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_prompt_template = PromptTemplate( \n",
    "    input_variables = ['email', 'code', 'instructions', 'solution'], \n",
    "    template = \"\"\"\n",
    "You are an assistant for Jeff Heaton, who is an adjunct instructor at Washington University\n",
    "in St. Louis. You should provide helpful responses to students via email queries that they\n",
    "send you. A student in my course is asking for help on an assignment. \n",
    "Please compose an email giving them help and code suggestions, but do not give them the entire \n",
    "solution. \n",
    "\n",
    "The student's email is given between the backwards ticks ``` and ```.\n",
    "```{email}```\n",
    "\n",
    "The student's code is given between the backward ticks ``` and ```.\n",
    "```{code}```\n",
    "\n",
    "The assignment instructions is given between the backwards ticks ``` and ```.\n",
    "```{instructions}```\n",
    "\n",
    "The solution to this assignment is given here between the backwards ticks ``` and ```.\n",
    "```{solution}```\n",
    "\"\"\")\n",
    "\n",
    "chain = email_prompt_template | llm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now call this chain with the provided data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = fetch_url_content(\"https://data.heatonresearch.com/wustl/CABI/genai-langchain/autohelp/autohelp_email_1.txt\")\n",
    "code = fetch_url_content(\"https://data.heatonresearch.com/wustl/CABI/genai-langchain/autohelp/autohelp_code_1.txt\")\n",
    "instructions = fetch_url_content(\"https://data.heatonresearch.com/wustl/CABI/genai-langchain/autohelp/autohelp_instructions_1.txt\")\n",
    "solution = fetch_url_content(\"https://data.heatonresearch.com/wustl/CABI/genai-langchain/autohelp/autohelp_solution_1.txt\")\n",
    "\n",
    "message = chain.invoke({\n",
    "    'email':email, \n",
    "    'code':code, \n",
    "    'instructions':instructions, \n",
    "    'solution':solution})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now examine the formatted response from the AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Dear Joe,\n",
       "\n",
       "Thank you for your email and for sharing your code. I understand your concerns, and I'll try to provide some guidance to help you with the assignment.\n",
       "\n",
       "1. **Model Selection (Regression or Classification):**\n",
       "The decision to use regression or classification models depends on the nature of the target variable (the variable you want to predict). In your case, since the target variable is a continuous numeric value (house price), it is indeed a regression problem. Using a regression model is the correct approach.\n",
       "\n",
       "2. **Loss Function:**\n",
       "For regression problems, the most common loss function is the mean squared error (MSE). This loss function measures the squared difference between the predicted values and the actual values. Cross-entropy loss is typically used for classification problems.\n",
       "\n",
       "3. **High Loss and Slow Training:**\n",
       "The high loss values and slow training time could be due to several reasons:\n",
       "- **Data Scaling**: It's essential to scale or normalize your input features before training a neural network. This helps the model converge faster and achieve better performance. You can use techniques like standardization (z-score normalization) or min-max scaling.\n",
       "- **Model Architecture**: The architecture of your neural network (number of layers, number of neurons per layer, activation functions) can significantly impact the model's performance. You may need to experiment with different architectures to find the one that works best for your problem.\n",
       "- **Learning Rate**: The learning rate is a hyperparameter that controls the step size during the optimization process. If the learning rate is too high, the model may diverge or oscillate, leading to high loss values. If it's too low, the training may be slow. You can try adjusting the learning rate or using techniques like learning rate schedulers.\n",
       "\n",
       "4. **Prediction Interpretation:**\n",
       "The small values (around 0.01 and 0.001) you're observing are likely due to the way the model is predicting the target variable. Neural networks often output values in a different scale than the original target variable. To interpret the predictions correctly, you may need to apply an inverse transformation or scaling to map the predicted values back to the original scale of the target variable.\n",
       "\n",
       "Here are some suggestions for your code:\n",
       "\n",
       "```python\n",
       "# Standardize input features\n",
       "x = df_houses_train[[\"bedrooms\", \"bathrooms\", \"garage\", \"land\", \"sqft\", \"median_income\"]].values\n",
       "x = (x - x.mean(axis=0)) / x.std(axis=0)\n",
       "\n",
       "# Try different model architectures\n",
       "model = Sequential()\n",
       "model.add(Dense(64, input_dim=x.shape[1], activation=\"relu\"))\n",
       "model.add(Dense(32, activation=\"relu\"))\n",
       "model.add(Dense(1))  # Output layer for regression\n",
       "\n",
       "# Adjust learning rate\n",
       "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
       "model.compile(optimizer=optimizer, loss=\"mean_squared_error\")\n",
       "\n",
       "# Monitor validation loss during training\n",
       "early_stop = EarlyStopping(monitor='val_loss', patience=10)\n",
       "model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=100, callbacks=[early_stop])\n",
       "```\n",
       "\n",
       "I hope these suggestions help you improve your model's performance. If you have any further questions or need additional assistance, feel free to reach out.\n",
       "\n",
       "Best regards,\n",
       "[Your Name]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display_markdown\n",
    "display_markdown(message.content,raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
